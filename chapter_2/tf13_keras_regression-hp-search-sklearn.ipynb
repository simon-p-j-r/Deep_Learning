{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
      "matplotlib 3.2.1\n",
      "numpy 1.18.5\n",
      "pandas 1.0.4\n",
      "sklearn 0.23.1\n",
      "tensorflow 2.2.0\n",
      "tensorflow.keras 2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n",
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "print(housing.DESCR)\n",
    "print(housing.data.shape)\n",
    "print(housing.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8) (11610,)\n",
      "(3870, 8) (3870,)\n",
      "(5160, 8) (5160,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state = 7)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train_all, y_train_all, random_state = 11)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.transform(x_valid)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1743 - val_loss: 0.6851\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5924 - val_loss: 0.6125\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5395 - val_loss: 0.5583\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5049 - val_loss: 0.5318\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4806 - val_loss: 0.5050\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4644 - val_loss: 0.4886\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4520 - val_loss: 0.4762\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4445 - val_loss: 0.4646\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4375 - val_loss: 0.4569\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4313 - val_loss: 0.4520\n"
     ]
    }
   ],
   "source": [
    "# RandomizedSearchCV\n",
    "# 1. 因为是sklearn的接口，转化为sklearn的model\n",
    "# 2. 定义参数集合\n",
    "# 3. 搜索参数\n",
    "\n",
    "def build_model(hidden_layers = 1,\n",
    "                layer_size = 30,\n",
    "                learning_rate = 3e-3):\n",
    "    model = keras.models.Sequential()\n",
    "    #因为不知道第一个输入的shape是多大的，因此我们需要单独从for循环里拿出来，for循环里的是输出再次作为输入\n",
    "    model.add(keras.layers.Dense(layer_size, activation='relu',\n",
    "                                 input_shape=x_train.shape[1:]))\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(keras.layers.Dense(layer_size,\n",
    "                                     activation = 'relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(loss = 'mse', optimizer = optimizer)\n",
    "    return model\n",
    "\n",
    "#KerasRegressor返回一个sk的model\n",
    "# build_fn是一个回调函数，要求了这个函数的返回值必须是一个深度学习的模型\n",
    "# 将深度学习的model直接包装成为一个sklearn的对象\n",
    "sklearn_model = tf.keras.wrappers.scikit_learn.KerasRegressor(\n",
    "    build_fn = build_model)\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=5, min_delta=1e-2)]\n",
    "#下面只是先对sk封装tf模型的一个测试\n",
    "history = sklearn_model.fit(x_train_scaled, y_train,\n",
    "                            epochs = 10,\n",
    "                            validation_data = (x_valid_scaled, y_valid),\n",
    "                            callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.show()\n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 5.7089 - val_loss: 5.5599\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 5.0553 - val_loss: 4.9995\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 4.5605 - val_loss: 4.5396\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 4.1457 - val_loss: 4.1476\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 3.7894 - val_loss: 3.8074\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3.5014\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 4.4897 - val_loss: 3.8663\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 2.9025 - val_loss: 2.4355\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.9278 - val_loss: 1.7604\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.5046 - val_loss: 1.4784\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.3268 - val_loss: 1.3439\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.2933\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 5.0239 - val_loss: 4.5894\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 3.8200 - val_loss: 3.5261\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 2.9329 - val_loss: 2.7507\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 2.3072 - val_loss: 2.2155\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.8947 - val_loss: 1.8734\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.7765\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 4.8012 - val_loss: 4.5169\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 3.9565 - val_loss: 3.6619\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 3.1469 - val_loss: 2.8778\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 2.4339 - val_loss: 2.2543\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.8906 - val_loss: 1.8413\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 2.1428\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 4.0042 - val_loss: 3.7358\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 3.1444 - val_loss: 2.9567\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 2.5281 - val_loss: 2.4257\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 2.1243 - val_loss: 2.0793\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.8632 - val_loss: 1.8519\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.8471\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 1.0380 - val_loss: 0.5819\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5342 - val_loss: 0.5100\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4816 - val_loss: 0.4642\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4560 - val_loss: 0.4487\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4441 - val_loss: 0.4483\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4059\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.0898 - val_loss: 0.6618\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5592 - val_loss: 0.5711\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5084 - val_loss: 0.5224\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4850 - val_loss: 0.5091\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4616 - val_loss: 0.4816\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4554\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 1.2494 - val_loss: 0.7706\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.6678 - val_loss: 0.6710\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5979 - val_loss: 0.5976\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5388 - val_loss: 0.5392\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4849 - val_loss: 0.4837\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4606\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.4644 - val_loss: 0.7353\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.6336 - val_loss: 0.6266\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5524 - val_loss: 0.5695\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4967 - val_loss: 0.5097\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4602 - val_loss: 0.4808\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4803\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.3003 - val_loss: 0.7950\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.6873 - val_loss: 0.6797\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5985 - val_loss: 0.6125\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5367 - val_loss: 0.5510\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4893 - val_loss: 0.4991\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4945\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 5.7942 - val_loss: 5.6044\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 5.0615 - val_loss: 4.9179\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 4.4343 - val_loss: 4.3032\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 3.8626 - val_loss: 3.7421\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 3.3499 - val_loss: 3.2490\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 3.0177\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 4.4619 - val_loss: 4.2032\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 3.6289 - val_loss: 3.4342\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 2.9679 - val_loss: 2.8241\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 2.4482 - val_loss: 2.3475\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 2.0445 - val_loss: 1.9789\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 1.8966\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 4.0217 - val_loss: 3.9045\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 3.5194 - val_loss: 3.3727\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 3.0672 - val_loss: 2.9469\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 2.6980 - val_loss: 2.6033\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 2.3981 - val_loss: 2.3284\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 2.1341\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 4.0506 - val_loss: 3.8699\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 3.5350 - val_loss: 3.3541\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 3.0559 - val_loss: 2.8858\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 2.6318 - val_loss: 2.4815\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 2.2741 - val_loss: 2.1535\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 2.3551\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 3.8555 - val_loss: 3.7968\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 3.3829 - val_loss: 3.3197\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 2.9316 - val_loss: 2.8704\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 2.5128 - val_loss: 2.4634\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 2.1420 - val_loss: 2.1124\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 2.0315\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.5466 - val_loss: 0.7957\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.6549 - val_loss: 0.6486\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5823 - val_loss: 0.5981\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5513 - val_loss: 0.5633\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5313 - val_loss: 0.5507\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4746\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.4187 - val_loss: 0.7459\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.6314 - val_loss: 0.6310\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.5492 - val_loss: 0.5565\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5004 - val_loss: 0.5119\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4819 - val_loss: 0.5072\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4663\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.3358 - val_loss: 0.7716\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.6586 - val_loss: 0.6699\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.5906 - val_loss: 0.6110\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5430 - val_loss: 0.5685\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5103 - val_loss: 0.5338\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4956\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.0305 - val_loss: 0.8768\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.7193 - val_loss: 0.6331\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5410 - val_loss: 0.5453\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4812 - val_loss: 0.5176\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4621 - val_loss: 0.4954\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4824\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.4401 - val_loss: 0.6960\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.6100 - val_loss: 0.5951\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5341 - val_loss: 0.5443\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4927 - val_loss: 0.5122\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.4701 - val_loss: 0.4906\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4831\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.2820 - val_loss: 0.8150\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.7360 - val_loss: 0.7741\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.6777 - val_loss: 0.6754\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.6687 - val_loss: 0.6400\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5829 - val_loss: 0.5808\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.5081\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.1860 - val_loss: 0.7311\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.7678 - val_loss: 0.7494\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.9054 - val_loss: 0.6179\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.5536 - val_loss: 0.5621\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5143 - val_loss: 0.5333\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.5081\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.6296 - val_loss: 0.7099\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.1757 - val_loss: 2.0094\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.6413 - val_loss: 0.5377\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5041 - val_loss: 0.5247\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.4866 - val_loss: 0.5014\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4838\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.1998 - val_loss: 0.8098\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.6990 - val_loss: 0.7155\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5866 - val_loss: 0.5822\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.5125 - val_loss: 0.5420\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4791 - val_loss: 0.5122\n",
      "73/73 [==============================] - 0s 994us/step - loss: 0.5002\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.2157 - val_loss: 0.8536\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.7142 - val_loss: 0.6371\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5613 - val_loss: 0.5714\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5179 - val_loss: 0.5357\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4901 - val_loss: 0.5140\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5051\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 8.6125 - val_loss: 8.3118\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 7.3526 - val_loss: 7.1817\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 6.3699 - val_loss: 6.2870\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 5.5841 - val_loss: 5.5656\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 4.9456 - val_loss: 4.9730\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 4.6312\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 5.3420 - val_loss: 5.2211\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 4.7368 - val_loss: 4.6465\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 4.2228 - val_loss: 4.1558\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 3.7827 - val_loss: 3.7346\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 3.4036 - val_loss: 3.3705\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 3.2938\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 9.0408 - val_loss: 8.9858\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 7.9419 - val_loss: 7.9489\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 7.0766 - val_loss: 7.1215\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 6.3755 - val_loss: 6.4450\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 5.7958 - val_loss: 5.8780\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 5.6308\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 9.9220 - val_loss: 9.3967\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 8.4767 - val_loss: 8.1304\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 7.3969 - val_loss: 7.1647\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 6.5654 - val_loss: 6.4102\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 5.9099 - val_loss: 5.8066\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 5.4712\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/291 [==============================] - 1s 2ms/step - loss: 7.8833 - val_loss: 7.6873\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 6.7642 - val_loss: 6.6532\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 5.9150 - val_loss: 5.8529\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 5.2545 - val_loss: 5.2191\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 4.7258 - val_loss: 4.7064\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 4.5623\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.9275 - val_loss: 0.7952\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.9884 - val_loss: 0.5539\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5280 - val_loss: 0.5027\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4766 - val_loss: 0.4849\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4492 - val_loss: 0.4572\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4048\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.2230 - val_loss: 0.6914\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.7224 - val_loss: 0.4882\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4410 - val_loss: 0.4617\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4240 - val_loss: 0.4430\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4112 - val_loss: 0.4341\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4186\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.6780 - val_loss: 0.5955\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4917 - val_loss: 0.4536\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4159 - val_loss: 0.4265\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.3982 - val_loss: 0.4197\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.3894 - val_loss: 0.3973\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.3960\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.9689 - val_loss: 0.6695\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5645 - val_loss: 0.6796\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5608 - val_loss: 0.6961\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.9329 - val_loss: 0.5580\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.4499 - val_loss: 0.4682\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4594\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.0938 - val_loss: 0.6706\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 0.5766 - val_loss: 0.5708\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5017 - val_loss: 0.5439\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4682 - val_loss: 0.9918\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5850 - val_loss: 0.4823\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4658\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 4.3043 - val_loss: 4.0919\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 3.6091 - val_loss: 3.4578\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 3.0497 - val_loss: 2.9491\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 2.6020 - val_loss: 2.5407\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 2.2458 - val_loss: 2.2170\n",
      "73/73 [==============================] - 0s 895us/step - loss: 1.9559\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 5.8676 - val_loss: 5.7152\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 5.1152 - val_loss: 5.0172\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 4.5074 - val_loss: 4.4390\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 3.9985 - val_loss: 3.9461\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 3.5630 - val_loss: 3.5205\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 3.4270\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 4.8911 - val_loss: 4.6813\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 4.0677 - val_loss: 3.9337\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 3.4300 - val_loss: 3.3504\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 2.9348 - val_loss: 2.8951\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 2.5475 - val_loss: 2.5366\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 2.3856\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 4.9691 - val_loss: 4.8939\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 4.3668 - val_loss: 4.3340\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 3.8664 - val_loss: 3.8647\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 3.4435 - val_loss: 3.4650\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 3.0831 - val_loss: 3.1240\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 2.9946\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 6.9562 - val_loss: 6.5647\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 5.6181 - val_loss: 5.4237\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 4.7075 - val_loss: 4.6147\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 4.0448 - val_loss: 4.0094\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 0s 2ms/step - loss: 3.5420 - val_loss: 3.5392\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 3.4415\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.1739 - val_loss: 0.5972\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5400 - val_loss: 0.5170\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 3ms/step - loss: 0.4775 - val_loss: 0.4659\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4427 - val_loss: 0.4475\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4174 - val_loss: 0.4136\n",
      "73/73 [==============================] - 0s 958us/step - loss: 0.3750\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.9453 - val_loss: 0.6183\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5269 - val_loss: 0.5336\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4706 - val_loss: 0.5310\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4347 - val_loss: 0.4611\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4143 - val_loss: 0.4296\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4211\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.1346 - val_loss: 0.6452\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5592 - val_loss: 0.5505\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4903 - val_loss: 0.4933\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4507 - val_loss: 0.4655\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4269 - val_loss: 0.4577\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4433\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.4214 - val_loss: 0.7033\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5845 - val_loss: 0.5746\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5046 - val_loss: 0.5329\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4797 - val_loss: 0.5060\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4586 - val_loss: 0.4814\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4890\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.2531 - val_loss: 0.6637\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5440 - val_loss: 0.5330\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4689 - val_loss: 0.4771\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4362 - val_loss: 0.4433\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4171 - val_loss: 0.4257\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4311\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.1124 - val_loss: 0.7577\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.6684 - val_loss: 0.6811\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.6175 - val_loss: 0.6343\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5784 - val_loss: 0.5941\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5447 - val_loss: 0.5590\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4926\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.8195 - val_loss: 0.7839\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.6246 - val_loss: 0.6032\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5345 - val_loss: 0.5495\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4962 - val_loss: 0.5105\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4679 - val_loss: 0.4891\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4678\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.4048 - val_loss: 0.6747\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.6024 - val_loss: 0.6133\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5521 - val_loss: 0.5698\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5141 - val_loss: 0.5339\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4873 - val_loss: 0.5109\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4747\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.0982 - val_loss: 0.7384\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.6209 - val_loss: 0.6445\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5518 - val_loss: 0.5812\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5116 - val_loss: 0.5420\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4868 - val_loss: 0.5193\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.5006\n",
      "Epoch 1/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 1.0163 - val_loss: 0.6364\n",
      "Epoch 2/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.5389 - val_loss: 0.5476\n",
      "Epoch 3/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4867 - val_loss: 0.5145\n",
      "Epoch 4/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4559 - val_loss: 0.4892\n",
      "Epoch 5/5\n",
      "291/291 [==============================] - 1s 2ms/step - loss: 0.4403 - val_loss: 0.4743\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4542\n",
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9864 - val_loss: 0.6826\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6449 - val_loss: 0.5003\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4525 - val_loss: 0.4527\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4230 - val_loss: 0.4338\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4076 - val_loss: 0.4174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f480a732e10>,\n",
       "                   param_distributions={'hidden_layers': [1, 2, 3, 4],\n",
       "                                        'layer_size': [5, 10, 20, 30],\n",
       "                                        'learning_rate': [0.0001, 5e-05, 0.001,\n",
       "                                                          0.005, 0.01]})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scipy也是sk中的\n",
    "from scipy.stats import reciprocal\n",
    "# 分布函数\n",
    "# f(x) = 1/(x*log(b/a)) a <= x <= b\n",
    "\n",
    "#sk 0.21.3版本可以用这种列表\n",
    "# param_distribution = {\n",
    "#     \"hidden_layers\":[1, 2, 3, 4],\n",
    "#     \"layer_size\": np.arange(1, 100),\n",
    "#     \"learning_rate\": reciprocal(1e-4, 1e-2),\n",
    "# }\n",
    "#最新版本只能用普通列表\n",
    "# 这里字典的键必须和build_model的形参名字一样，不一样直接报错\n",
    "param_distribution = {\n",
    "    \"hidden_layers\": [1, 2, 3, 4],\n",
    "    \"layer_size\": [5, 10, 20, 30],\n",
    "    \"learning_rate\": [1e-4, 5e-5, 1e-3, 5e-3, 1e-2],\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "# 网格搜索会将每个参数都交叉搭配查找最佳值，比如这个例子就是4*4*5=80次\n",
    "#随机搜索是随机的选值，反正次数肯定没有网格的多\n",
    "random_search_cv = RandomizedSearchCV(sklearn_model,\n",
    "                                      param_distribution)\n",
    "# grid_search_cv =GridSearchCV(sklearn_model,param_distribution)\n",
    "random_search_cv.fit(x_train_scaled, y_train, epochs = 5,\n",
    "                     validation_data = (x_valid_scaled, y_valid),\n",
    "                     callbacks = callbacks)\n",
    "\n",
    "# grid_search_cv.fit(x_train_scaled, y_train, epochs = 5,\n",
    "#                      validation_data = (x_valid_scaled, y_valid),\n",
    "#                      callbacks = callbacks)\n",
    "# cross_validation: 训练集分成n份，n-1训练，最后一份验证."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'layer_size': 20, 'hidden_layers': 1}\n",
      "-0.4289206027984619\n",
      "<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f48940a8400>\n"
     ]
    }
   ],
   "source": [
    "print(random_search_cv.best_params_)\n",
    "# 这个损失会加一个自动负号\n",
    "print(random_search_cv.best_score_)\n",
    "print(random_search_cv.best_estimator_)\n",
    "\n",
    "# print(grid_search_cv.best_params_)\n",
    "# print(grid_search_cv.best_score_)\n",
    "# print(grid_search_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4210195541381836"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#拿最佳的模型\n",
    "model = random_search_cv.best_estimator_.model\n",
    "\n",
    "model.evaluate(x_test_scaled, y_test)\n",
    "\n",
    "# model = grid_search_cv.best_estimator_.model\n",
    "# model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
