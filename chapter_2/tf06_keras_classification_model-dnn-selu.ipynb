{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
      "matplotlib 3.2.1\n",
      "numpy 1.18.5\n",
      "pandas 1.0.4\n",
      "sklearn 0.23.1\n",
      "tensorflow 2.2.0\n",
      "tensorflow.keras 2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 28, 28) (5000,)\n",
      "(55000, 28, 28) (55000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train_all, y_train_all), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_valid, x_train = x_train_all[:5000], x_train_all[5000:]\n",
    "y_valid, y_train = y_train_all[:5000], y_train_all[5000:]\n",
    "\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = (x - u) / std\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# x_train: [None, 28, 28] -> [None, 784]\n",
    "x_train_scaled = scaler.fit_transform(\n",
    "    x_train.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28)\n",
    "x_valid_scaled = scaler.transform(\n",
    "    x_valid.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28)\n",
    "x_test_scaled = scaler.transform(\n",
    "    x_test.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.models.Sequential()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation=\"selu\"))#把之前的relu改为了selu\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer = keras.optimizers.SGD(0.001),\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dense in module tensorflow.python.keras.layers.core:\n",
      "\n",
      "class Dense(tensorflow.python.keras.engine.base_layer.Layer)\n",
      " |  Just your regular densely-connected NN layer.\n",
      " |  \n",
      " |  `Dense` implements the operation:\n",
      " |  `output = activation(dot(input, kernel) + bias)`\n",
      " |  where `activation` is the element-wise activation function\n",
      " |  passed as the `activation` argument, `kernel` is a weights matrix\n",
      " |  created by the layer, and `bias` is a bias vector created by the layer\n",
      " |  (only applicable if `use_bias` is `True`).\n",
      " |  \n",
      " |  Note: If the input to the layer has a rank greater than 2, then `Dense`\n",
      " |  computes the dot product between the `inputs` and the `kernel` along the\n",
      " |  last axis of the `inputs` and axis 1 of the `kernel` (using `tf.tensordot`).\n",
      " |  For example, if input has dimensions `(batch_size, d0, d1)`,\n",
      " |  then we create a `kernel` with shape `(d1, units)`, and the `kernel` operates\n",
      " |  along axis 2 of the `input`, on every sub-tensor of shape `(1, 1, d1)`\n",
      " |  (there are `batch_size * d0` such sub-tensors).\n",
      " |  The output in this case will have shape `(batch_size, d0, units)`.\n",
      " |  \n",
      " |  Besides, layer attributes cannot be modified after the layer has been called\n",
      " |  once (except the `trainable` attribute).\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  ```python\n",
      " |  # as first layer in a sequential model:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, input_shape=(16,)))\n",
      " |  # now the model will take as input arrays of shape (*, 16)\n",
      " |  # and output arrays of shape (*, 32)\n",
      " |  \n",
      " |  # after the first layer, you don't need to specify\n",
      " |  # the size of the input anymore:\n",
      " |  model.add(Dense(32))\n",
      " |  ```\n",
      " |  \n",
      " |  Arguments:\n",
      " |    units: Positive integer, dimensionality of the output space.\n",
      " |    activation: Activation function to use.\n",
      " |      If you don't specify anything, no activation is applied\n",
      " |      (ie. \"linear\" activation: `a(x) = x`).\n",
      " |    use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
      " |    bias_initializer: Initializer for the bias vector.\n",
      " |    kernel_regularizer: Regularizer function applied to\n",
      " |      the `kernel` weights matrix.\n",
      " |    bias_regularizer: Regularizer function applied to the bias vector.\n",
      " |    activity_regularizer: Regularizer function applied to\n",
      " |      the output of the layer (its \"activation\")..\n",
      " |    kernel_constraint: Constraint function applied to\n",
      " |      the `kernel` weights matrix.\n",
      " |    bias_constraint: Constraint function applied to the bias vector.\n",
      " |  \n",
      " |  Input shape:\n",
      " |    N-D tensor with shape: `(batch_size, ..., input_dim)`.\n",
      " |    The most common situation would be\n",
      " |    a 2D input with shape `(batch_size, input_dim)`.\n",
      " |  \n",
      " |  Output shape:\n",
      " |    N-D tensor with shape: `(batch_size, ..., units)`.\n",
      " |    For instance, for a 2D input with shape `(batch_size, input_dim)`,\n",
      " |    the output would have shape `(batch_size, units)`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dense\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      tensorflow.python.keras.utils.version_utils.LayerVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        *args: Positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(inputs, self):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(x.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        inputs: Ignored when executing eagerly. If anything other than None is\n",
      " |          passed, it signals the losses are conditional on some of the layer's\n",
      " |          inputs, and thus they should only be run where these inputs are\n",
      " |          available. This is the case for activity regularization losses, for\n",
      " |          instance. If `None` is passed, the losses are assumed\n",
      " |          to be unconditional, and will apply across all dataflows of the layer\n",
      " |          (e.g. weight regularization losses).\n",
      " |  \n",
      " |  add_metric(self, value, aggregation=None, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
      " |          it indicates that the metric tensor provided has been aggregated\n",
      " |          already. eg, `bin_acc = BinaryAccuracy(name='acc')` followed by\n",
      " |          `model.add_metric(bin_acc(y_true, y_pred))`. If aggregation='mean', the\n",
      " |          given metric tensor will be sample-wise reduced using `mean` function.\n",
      " |          eg, `model.add_metric(tf.reduce_sum(outputs), name='output_mean',\n",
      " |          aggregation='mean')`.\n",
      " |        name: String metric name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      `inputs` is now automatically inferred\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.add_weight` method instead.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created variable. Usually either a `Variable` or `ResourceVariable`\n",
      " |        instance. If `partitioner` is not `None`, a `PartitionedVariable`\n",
      " |        instance is returned.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called with partitioned variable regularization and\n",
      " |          eager execution is enabled.\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.__call__` method instead.\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      returns both trainable and non-trainable weight values associated with this\n",
      " |      layer as a list of Numpy arrays, which can in turn be used to load state\n",
      " |      into similarly parameterized layers.\n",
      " |      \n",
      " |      For example, a Dense layer returns a list of two values-- per-output\n",
      " |      weights and the bias value. These can be used to set the weights of another\n",
      " |      Dense layer:\n",
      " |      \n",
      " |      >>> a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b.set_weights(a.get_weights())\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a Dense layer returns a list of two values-- per-output\n",
      " |      weights and the bias value. These can be used to set the weights of another\n",
      " |      Dense layer:\n",
      " |      \n",
      " |      >>> a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> b.set_weights(a.get_weights())\n",
      " |      >>> b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  dtype\n",
      " |      Dtype used by the weights of the layer, set in the constructor.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
      " |      the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
      " |      of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
      " |      error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  losses\n",
      " |      Losses which are associated with this `Layer`.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |      List of `tf.keras.metrics.Metric` instances tracked by the layer.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are expected\n",
      " |      to be updated manually in `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from tensorflow.python.keras.utils.version_utils.LayerVersionSelector:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(keras.layers.Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,410\n",
      "Trainable params: 271,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.6853 - accuracy: 0.7569 - val_loss: 0.5183 - val_accuracy: 0.8232\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4812 - accuracy: 0.8255 - val_loss: 0.4574 - val_accuracy: 0.8368\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4302 - accuracy: 0.8428 - val_loss: 0.4420 - val_accuracy: 0.8412\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3995 - accuracy: 0.8564 - val_loss: 0.4077 - val_accuracy: 0.8542\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3776 - accuracy: 0.8624 - val_loss: 0.3940 - val_accuracy: 0.8566\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3600 - accuracy: 0.8697 - val_loss: 0.3973 - val_accuracy: 0.8568\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3454 - accuracy: 0.8740 - val_loss: 0.3781 - val_accuracy: 0.8612\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3329 - accuracy: 0.8800 - val_loss: 0.3747 - val_accuracy: 0.8620\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3218 - accuracy: 0.8826 - val_loss: 0.3767 - val_accuracy: 0.8602\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3118 - accuracy: 0.8868 - val_loss: 0.3621 - val_accuracy: 0.8658\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3033 - accuracy: 0.8903 - val_loss: 0.3592 - val_accuracy: 0.8658\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2946 - accuracy: 0.8932 - val_loss: 0.3775 - val_accuracy: 0.8628\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2876 - accuracy: 0.8949 - val_loss: 0.3586 - val_accuracy: 0.8696\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2809 - accuracy: 0.8973 - val_loss: 0.3574 - val_accuracy: 0.8670\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2741 - accuracy: 0.9004 - val_loss: 0.3526 - val_accuracy: 0.8724\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2670 - accuracy: 0.9021 - val_loss: 0.3494 - val_accuracy: 0.8754\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2612 - accuracy: 0.9045 - val_loss: 0.3487 - val_accuracy: 0.8732\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2556 - accuracy: 0.9051 - val_loss: 0.3494 - val_accuracy: 0.8686\n",
      "Epoch 19/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2507 - accuracy: 0.9074 - val_loss: 0.3576 - val_accuracy: 0.8720\n",
      "Epoch 20/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2459 - accuracy: 0.9095 - val_loss: 0.3584 - val_accuracy: 0.8754\n",
      "Epoch 21/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.2394 - accuracy: 0.9118 - val_loss: 0.3489 - val_accuracy: 0.8730\n"
     ]
    }
   ],
   "source": [
    "# Tensorboard, earlystopping, ModelCheckpoint\n",
    "logdir = './dnn-selu-callbacks'\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "output_model_file = os.path.join(logdir,\n",
    "                                 \"fashion_mnist_model.h5\")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(logdir),\n",
    "    keras.callbacks.ModelCheckpoint(output_model_file,\n",
    "                                    save_best_only = True),\n",
    "    keras.callbacks.EarlyStopping(patience=5, min_delta=1e-3),\n",
    "]\n",
    "history = model.fit(x_train_scaled, y_train, epochs=100,\n",
    "                    validation_data=(x_valid_scaled, y_valid),\n",
    "                    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.6853417754173279, 0.4811970591545105, 0.43016889691352844, 0.3995111882686615, 0.3775902986526489, 0.3600160479545593, 0.3454486131668091, 0.3328794836997986, 0.32182347774505615, 0.3118446171283722, 0.3032621741294861, 0.29461097717285156, 0.2875731289386749, 0.2808607816696167, 0.27413681149482727, 0.2670440375804901, 0.26120951771736145, 0.2555902600288391, 0.2507016658782959, 0.2459203004837036, 0.23935569822788239], 'accuracy': [0.7568727135658264, 0.8255454301834106, 0.8428182005882263, 0.8563636541366577, 0.8623636364936829, 0.8696908950805664, 0.8740181922912598, 0.8799818158149719, 0.8825818300247192, 0.8867636322975159, 0.8903454542160034, 0.8931636214256287, 0.8949454426765442, 0.8973454833030701, 0.9003999829292297, 0.9020909070968628, 0.9044545292854309, 0.9051454663276672, 0.9073818325996399, 0.9094908833503723, 0.9118363857269287], 'val_loss': [0.5183234214782715, 0.45738378167152405, 0.44200658798217773, 0.4077020585536957, 0.3940220773220062, 0.39733803272247314, 0.37811917066574097, 0.3746606111526489, 0.37673187255859375, 0.362112820148468, 0.3592456877231598, 0.37748730182647705, 0.3586139678955078, 0.3574312925338745, 0.3526308834552765, 0.3494391441345215, 0.3487387001514435, 0.3494080901145935, 0.35762667655944824, 0.3584353029727936, 0.34887248277664185], 'val_accuracy': [0.823199987411499, 0.8367999792098999, 0.8411999940872192, 0.854200005531311, 0.8565999865531921, 0.8568000197410583, 0.8611999750137329, 0.8619999885559082, 0.8601999878883362, 0.8658000230789185, 0.8658000230789185, 0.8628000020980835, 0.8695999979972839, 0.8669999837875366, 0.8723999857902527, 0.8754000067710876, 0.873199999332428, 0.8686000108718872, 0.871999979019165, 0.8754000067710876, 0.8730000257492065]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(history)\n",
    "\n",
    "# 1. 参数众多，训练不充分\n",
    "# 2. 梯度消失 -> 链式法则 -> 复合函数f(g(x))\n",
    "#    selu缓解梯度消失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3881970942020416, 0.8700000047683716]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
