{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
      "matplotlib 3.2.1\n",
      "numpy 1.18.5\n",
      "pandas 1.0.4\n",
      "sklearn 0.23.1\n",
      "tensorflow 2.2.0\n",
      "tensorflow.keras 2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 28, 28) (5000,)\n",
      "(55000, 28, 28) (55000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train_all, y_train_all), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_valid, x_train = x_train_all[:5000], x_train_all[5000:]\n",
    "y_valid, y_train = y_train_all[:5000], y_train_all[5000:]\n",
    "\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = (x - u) / std\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# x_train: [None, 28, 28] -> [None, 784]\n",
    "#先reshape变为一维的目的是对每一个像素点进行标准化（让其等价）\n",
    "#同时StandardScaler只能对二维的进行标准化\n",
    "x_train_scaled = scaler.fit_transform(\n",
    "    x_train.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28)\n",
    "x_valid_scaled = scaler.transform(\n",
    "    x_valid.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28)\n",
    "x_test_scaled = scaler.transform(\n",
    "    x_test.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.models.Sequential()\n",
    "#批归一化为了防止梯度消失\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "    #只要在模型中加入下面代码即可\n",
    "#     注意一般是放在Dense的后面，因为你一开始的数据一般就经过了例如归一化的操作处理\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \"\"\"\n",
    "    #也可以把激活函数放在批归一化的后面\n",
    "    model.add(keras.layers.Dense(100))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    \"\"\"\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer = keras.optimizers.SGD(0.001),\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 279,410\n",
      "Trainable params: 275,410\n",
      "Non-trainable params: 4,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(784, 100) dtype=float32, numpy=\n",
       " array([[-0.07478273, -0.0556508 , -0.01557904, ..., -0.03644999,\n",
       "          0.00165067, -0.0170146 ],\n",
       "        [-0.07964948, -0.07395523,  0.07215215, ...,  0.07652894,\n",
       "         -0.01340353, -0.02210955],\n",
       "        [ 0.07526574, -0.07637163,  0.01429589, ..., -0.04525102,\n",
       "         -0.08105586,  0.01270841],\n",
       "        ...,\n",
       "        [ 0.00340949,  0.05726895, -0.02280001, ..., -0.01853073,\n",
       "         -0.01364163, -0.05723184],\n",
       "        [ 0.02636699, -0.05048181,  0.05457503, ..., -0.05764081,\n",
       "         -0.07415691, -0.02419814],\n",
       "        [ 0.0494184 , -0.07247749, -0.01420894, ...,  0.0632699 ,\n",
       "         -0.03815976,  0.0016512 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization/gamma:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization/beta:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization/moving_mean:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization/moving_variance:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[ 0.13040853,  0.12536263,  0.1306088 , ..., -0.13171825,\n",
       "          0.15579325,  0.09986621],\n",
       "        [ 0.10213351,  0.13369352, -0.00116012, ...,  0.0194266 ,\n",
       "          0.10784176,  0.14613965],\n",
       "        [ 0.1355201 ,  0.12997013, -0.02824624, ..., -0.10994294,\n",
       "         -0.11926427,  0.16967136],\n",
       "        ...,\n",
       "        [ 0.04111782,  0.04597767, -0.06968364, ..., -0.07916307,\n",
       "          0.15564874, -0.05786294],\n",
       "        [-0.1067257 ,  0.06638877,  0.01797895, ...,  0.00133938,\n",
       "          0.10702911,  0.01047967],\n",
       "        [-0.16063544, -0.05628823, -0.11453122, ...,  0.10258278,\n",
       "         -0.12617663,  0.09535941]], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_1/gamma:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_1/beta:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_1/moving_mean:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_1/moving_variance:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_2/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[ 0.00846615,  0.03822748, -0.08784098, ..., -0.1528967 ,\n",
       "         -0.12601742,  0.07555299],\n",
       "        [ 0.07109711,  0.11126444, -0.08039676, ..., -0.03637889,\n",
       "         -0.17157891, -0.04422067],\n",
       "        [ 0.15298763, -0.10206239,  0.14627469, ..., -0.03904921,\n",
       "         -0.02043989,  0.0734646 ],\n",
       "        ...,\n",
       "        [ 0.06064868, -0.13310274,  0.17269447, ..., -0.1474228 ,\n",
       "         -0.15686823, -0.0252658 ],\n",
       "        [ 0.0705269 ,  0.01750492,  0.17129749, ..., -0.16390781,\n",
       "          0.10342744, -0.10371631],\n",
       "        [-0.05619007,  0.04427522,  0.11240599, ..., -0.0305776 ,\n",
       "          0.07670736,  0.16844621]], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_2/gamma:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_2/beta:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_2/moving_mean:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_2/moving_variance:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[ 0.04348487, -0.16372   ,  0.16115713, ..., -0.08649856,\n",
       "         -0.11601665, -0.1718209 ],\n",
       "        [ 0.00422059, -0.15051554, -0.05019234, ..., -0.10022251,\n",
       "          0.13740423,  0.15183917],\n",
       "        [ 0.05173534,  0.04465477, -0.0353058 , ...,  0.11886096,\n",
       "         -0.08318461,  0.05138808],\n",
       "        ...,\n",
       "        [-0.1667602 ,  0.10348302,  0.1520186 , ...,  0.11402163,\n",
       "          0.0584362 ,  0.04913436],\n",
       "        [-0.10588724, -0.09775157,  0.16366145, ...,  0.03633855,\n",
       "         -0.02240312, -0.05389385],\n",
       "        [-0.16426621,  0.14769503, -0.06419253, ...,  0.07555187,\n",
       "         -0.16353276, -0.09564555]], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_3/gamma:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_3/beta:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_3/moving_mean:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_3/moving_variance:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_4/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[-2.5958225e-02, -3.5506949e-02, -6.9263548e-02, ...,\n",
       "         -1.5856718e-01, -1.1647090e-01, -1.6727223e-01],\n",
       "        [-7.1358003e-02, -8.9878619e-02, -1.6552329e-01, ...,\n",
       "         -9.1135502e-05,  8.3146691e-02, -4.2174459e-03],\n",
       "        [-7.1553208e-02, -1.1012893e-01, -8.8932954e-02, ...,\n",
       "          3.9129168e-02, -2.2262335e-02,  3.0591398e-02],\n",
       "        ...,\n",
       "        [ 1.0812417e-01,  6.1805576e-02, -2.6759684e-02, ...,\n",
       "         -1.4947267e-01,  1.5071949e-01,  3.5712123e-04],\n",
       "        [ 1.2680876e-01, -9.4936259e-02, -1.5944830e-01, ...,\n",
       "         -1.3326780e-01, -1.5120488e-01,  4.3665826e-02],\n",
       "        [ 9.9396974e-02,  1.6577947e-01,  1.7165348e-01, ...,\n",
       "          1.3493729e-01,  9.3708187e-02,  1.4111549e-01]], dtype=float32)>,\n",
       " <tf.Variable 'dense_4/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_4/gamma:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_4/beta:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_4/moving_mean:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_4/moving_variance:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_5/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[ 0.04846054,  0.12727189,  0.11067623, ...,  0.1417703 ,\n",
       "         -0.11432049,  0.06380343],\n",
       "        [-0.14045893,  0.12783879,  0.12211621, ..., -0.07217854,\n",
       "         -0.09945199, -0.15200394],\n",
       "        [ 0.10359547,  0.16366726,  0.07357933, ..., -0.07810987,\n",
       "         -0.1443745 ,  0.02716884],\n",
       "        ...,\n",
       "        [-0.16276212, -0.04763097,  0.07079506, ..., -0.1664879 ,\n",
       "          0.03843445, -0.08962242],\n",
       "        [-0.08830015,  0.02141736,  0.13819239, ...,  0.08628008,\n",
       "          0.1128332 , -0.02838834],\n",
       "        [ 0.09051618,  0.11544645, -0.10946048, ...,  0.01859157,\n",
       "         -0.08442491, -0.06473584]], dtype=float32)>,\n",
       " <tf.Variable 'dense_5/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_5/gamma:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_5/beta:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_5/moving_mean:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_5/moving_variance:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_6/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[ 0.16938075,  0.08393943,  0.07919565, ..., -0.10625799,\n",
       "         -0.05075557, -0.15524186],\n",
       "        [-0.01332426,  0.16888109, -0.13912076, ..., -0.04375139,\n",
       "          0.03356656, -0.01668252],\n",
       "        [-0.15723164,  0.07385054,  0.13151124, ...,  0.06825306,\n",
       "         -0.16254205,  0.14012897],\n",
       "        ...,\n",
       "        [ 0.08698845,  0.05167025,  0.06643957, ..., -0.1319153 ,\n",
       "          0.13455725, -0.14810182],\n",
       "        [-0.09904548, -0.14204916, -0.03156477, ..., -0.1258486 ,\n",
       "          0.02507158,  0.0298084 ],\n",
       "        [-0.03699262, -0.05145912,  0.10278329, ..., -0.04169323,\n",
       "          0.1461151 ,  0.03517617]], dtype=float32)>,\n",
       " <tf.Variable 'dense_6/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_6/gamma:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_6/beta:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_6/moving_mean:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_6/moving_variance:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_7/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[ 0.00839782,  0.15064153,  0.11410642, ...,  0.03379679,\n",
       "          0.0723481 , -0.08283133],\n",
       "        [ 0.15074861,  0.01318832,  0.1266489 , ...,  0.14527336,\n",
       "          0.15274474,  0.04131967],\n",
       "        [ 0.05595621, -0.16960731,  0.15353397, ...,  0.15902328,\n",
       "          0.15694043,  0.1384413 ],\n",
       "        ...,\n",
       "        [-0.08808871,  0.05831273, -0.11383316, ..., -0.01408839,\n",
       "         -0.1515981 , -0.096035  ],\n",
       "        [ 0.14433151, -0.09983   , -0.12889397, ...,  0.1008524 ,\n",
       "          0.10304514, -0.08621193],\n",
       "        [ 0.00978604,  0.02402446, -0.02716269, ..., -0.10382747,\n",
       "          0.03881553, -0.04026759]], dtype=float32)>,\n",
       " <tf.Variable 'dense_7/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_7/gamma:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_7/beta:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_7/moving_mean:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_7/moving_variance:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_8/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[ 0.08967835, -0.00606388, -0.16011636, ...,  0.02773765,\n",
       "         -0.02324823, -0.01238091],\n",
       "        [ 0.13502851, -0.02824186, -0.07115132, ..., -0.15233798,\n",
       "          0.03617156, -0.04324354],\n",
       "        [ 0.13699132,  0.02454002, -0.07342541, ...,  0.07929045,\n",
       "         -0.10027752,  0.17035615],\n",
       "        ...,\n",
       "        [-0.06251461,  0.05557564,  0.12675148, ...,  0.04418325,\n",
       "          0.01354061,  0.16839883],\n",
       "        [ 0.08570433,  0.13307813, -0.1425614 , ...,  0.14611349,\n",
       "         -0.10128707, -0.13433534],\n",
       "        [ 0.01128981,  0.00797899,  0.12418017, ..., -0.02207139,\n",
       "         -0.11935256, -0.13550779]], dtype=float32)>,\n",
       " <tf.Variable 'dense_8/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_8/gamma:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_8/beta:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_8/moving_mean:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_8/moving_variance:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_9/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[ 4.17543054e-02, -7.87210390e-02,  7.74280727e-02, ...,\n",
       "         -2.65291333e-02,  3.46042365e-02, -1.35515019e-01],\n",
       "        [ 9.44652557e-02, -4.46505547e-02,  5.71838468e-02, ...,\n",
       "         -3.63376439e-02,  1.71950310e-01,  8.52057338e-02],\n",
       "        [ 7.23335296e-02,  1.04443103e-01,  1.72734976e-01, ...,\n",
       "         -9.74862501e-02, -4.34727222e-02, -4.73398715e-02],\n",
       "        ...,\n",
       "        [-3.13225687e-02, -1.47910342e-01, -1.04277633e-01, ...,\n",
       "         -1.64379030e-01,  6.17622584e-02, -4.03777659e-02],\n",
       "        [ 1.00969464e-01,  6.21309876e-02, -1.17999524e-01, ...,\n",
       "          1.39857024e-01, -2.49231160e-02, -1.69174656e-01],\n",
       "        [-1.78967714e-02,  1.13233089e-01,  7.92095959e-02, ...,\n",
       "         -1.04411922e-01, -1.63922548e-01,  3.00556421e-05]], dtype=float32)>,\n",
       " <tf.Variable 'dense_9/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_9/gamma:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_9/beta:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_9/moving_mean:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_9/moving_variance:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_10/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[-0.05574764, -0.03126477,  0.07618658, ...,  0.01673125,\n",
       "          0.13420793,  0.14690873],\n",
       "        [ 0.13627473, -0.10968914, -0.1207291 , ...,  0.00674345,\n",
       "          0.05096303,  0.0760546 ],\n",
       "        [ 0.01958045,  0.05218674,  0.1539886 , ..., -0.13323522,\n",
       "          0.09357101,  0.15618208],\n",
       "        ...,\n",
       "        [ 0.12498033,  0.11215198,  0.05111219, ...,  0.01991573,\n",
       "         -0.01808333, -0.02962464],\n",
       "        [-0.01257165,  0.13313928, -0.0152241 , ...,  0.14804596,\n",
       "          0.03571498,  0.03610432],\n",
       "        [-0.08505747,  0.09980848, -0.06663539, ..., -0.05498619,\n",
       "         -0.08763967, -0.00152735]], dtype=float32)>,\n",
       " <tf.Variable 'dense_10/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_10/gamma:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_10/beta:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_10/moving_mean:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_10/moving_variance:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_11/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[-0.1454526 , -0.12479252, -0.01484153, ..., -0.01943271,\n",
       "         -0.16845596, -0.12353805],\n",
       "        [ 0.01172531, -0.16731071, -0.14227584, ..., -0.12701719,\n",
       "         -0.13989252,  0.14833906],\n",
       "        [-0.14120229, -0.10143556, -0.09510954, ...,  0.03474417,\n",
       "         -0.10786723,  0.16789007],\n",
       "        ...,\n",
       "        [ 0.14199573,  0.074598  ,  0.04676715, ...,  0.01338534,\n",
       "          0.07327224,  0.15537116],\n",
       "        [-0.04621547,  0.04759507,  0.02344504, ..., -0.13493346,\n",
       "          0.08629274, -0.15161374],\n",
       "        [ 0.05678146, -0.11459626,  0.04415794, ...,  0.16349614,\n",
       "          0.06687453,  0.03395465]], dtype=float32)>,\n",
       " <tf.Variable 'dense_11/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_11/gamma:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_11/beta:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_11/moving_mean:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_11/moving_variance:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_12/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[ 0.07889387,  0.08676594,  0.07319605, ...,  0.0839107 ,\n",
       "         -0.0876189 ,  0.00520742],\n",
       "        [ 0.08875996,  0.1729218 ,  0.14118329, ..., -0.1494806 ,\n",
       "          0.045315  , -0.10324884],\n",
       "        [ 0.06435606,  0.04834297,  0.03439663, ...,  0.16941553,\n",
       "         -0.11359745,  0.09504744],\n",
       "        ...,\n",
       "        [ 0.13730928,  0.10684922, -0.16448963, ...,  0.06069341,\n",
       "         -0.01885019,  0.01400626],\n",
       "        [ 0.16803738, -0.07823223, -0.16788578, ...,  0.11276445,\n",
       "         -0.15133698,  0.02295981],\n",
       "        [ 0.0466914 ,  0.16755566,  0.13480291, ...,  0.01192142,\n",
       "          0.02182011,  0.10119218]], dtype=float32)>,\n",
       " <tf.Variable 'dense_12/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_12/gamma:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_12/beta:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_12/moving_mean:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_12/moving_variance:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_13/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[-0.07768432, -0.02481943,  0.1306273 , ..., -0.0007809 ,\n",
       "         -0.10614129,  0.05966131],\n",
       "        [ 0.06950021, -0.0119694 ,  0.04591241, ..., -0.03341116,\n",
       "         -0.00081328, -0.01569201],\n",
       "        [ 0.00810978,  0.16803762, -0.10803794, ...,  0.14509317,\n",
       "         -0.00069095,  0.00652248],\n",
       "        ...,\n",
       "        [ 0.13438213,  0.00606455, -0.05758598, ..., -0.11415754,\n",
       "         -0.07916228,  0.07657716],\n",
       "        [ 0.15366   ,  0.09116852, -0.05126767, ...,  0.15065184,\n",
       "         -0.02692586, -0.12646218],\n",
       "        [ 0.04194988,  0.04405338, -0.14612728, ..., -0.11578366,\n",
       "          0.10187712, -0.12665837]], dtype=float32)>,\n",
       " <tf.Variable 'dense_13/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_13/gamma:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_13/beta:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_13/moving_mean:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_13/moving_variance:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_14/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[-0.08316652, -0.05743153, -0.00639218, ...,  0.02312718,\n",
       "         -0.06678058,  0.09312472],\n",
       "        [-0.00873566, -0.06838515,  0.12025982, ..., -0.03757307,\n",
       "         -0.12439604, -0.07945849],\n",
       "        [ 0.13096899, -0.12522191, -0.01754026, ...,  0.04839566,\n",
       "          0.13410449, -0.09168847],\n",
       "        ...,\n",
       "        [ 0.16014662,  0.11056894, -0.0697455 , ...,  0.1520653 ,\n",
       "          0.14859143,  0.11139673],\n",
       "        [ 0.02003013, -0.02762495,  0.09951773, ...,  0.04894044,\n",
       "         -0.01969002,  0.14204413],\n",
       "        [-0.01692781,  0.01308644,  0.12535146, ...,  0.06193548,\n",
       "         -0.14447135, -0.06149644]], dtype=float32)>,\n",
       " <tf.Variable 'dense_14/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_14/gamma:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_14/beta:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_14/moving_mean:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_14/moving_variance:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_15/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[-0.12660183,  0.12370023,  0.09849617, ..., -0.14413516,\n",
       "         -0.03700498, -0.03387268],\n",
       "        [-0.16430557, -0.08074484,  0.0179607 , ...,  0.09843153,\n",
       "          0.11334842, -0.12949936],\n",
       "        [-0.09467755,  0.10544595,  0.10283667, ...,  0.07687882,\n",
       "          0.02945313, -0.12993664],\n",
       "        ...,\n",
       "        [ 0.03208525, -0.10151039, -0.0399065 , ..., -0.04703297,\n",
       "          0.08513358,  0.17227644],\n",
       "        [-0.03384605, -0.04115532,  0.09002921, ..., -0.0746352 ,\n",
       "         -0.12223122, -0.04388705],\n",
       "        [-0.06291563, -0.00382151,  0.04528064, ..., -0.0901076 ,\n",
       "          0.02972811,  0.09984845]], dtype=float32)>,\n",
       " <tf.Variable 'dense_15/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_15/gamma:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_15/beta:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_15/moving_mean:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_15/moving_variance:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_16/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[-0.14780198,  0.02301359, -0.15754503, ...,  0.05332392,\n",
       "         -0.13974811,  0.13973239],\n",
       "        [-0.01448449, -0.1260311 ,  0.15816924, ...,  0.15092325,\n",
       "         -0.1294994 ,  0.1442473 ],\n",
       "        [-0.06548788, -0.08520919, -0.01380499, ..., -0.14187887,\n",
       "         -0.07737993,  0.00855246],\n",
       "        ...,\n",
       "        [-0.02846758,  0.08928677,  0.13066834, ...,  0.10359102,\n",
       "          0.08033139,  0.00023174],\n",
       "        [ 0.1145201 ,  0.10996091,  0.06986555, ..., -0.09881517,\n",
       "         -0.12381895, -0.08090734],\n",
       "        [ 0.1393438 , -0.14733592, -0.10152996, ...,  0.01463498,\n",
       "         -0.05421607, -0.0917234 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense_16/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_16/gamma:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_16/beta:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_16/moving_mean:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_16/moving_variance:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_17/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[-0.1649333 ,  0.111691  ,  0.16419592, ...,  0.17182317,\n",
       "         -0.10137177,  0.1469982 ],\n",
       "        [ 0.06567448, -0.08419378, -0.06310014, ..., -0.17245573,\n",
       "          0.16664636, -0.13580322],\n",
       "        [ 0.02593672, -0.14753187, -0.16670024, ...,  0.08628732,\n",
       "         -0.06555796, -0.06586936],\n",
       "        ...,\n",
       "        [-0.00914451,  0.04464559, -0.14267479, ..., -0.01391301,\n",
       "         -0.11522457,  0.15155461],\n",
       "        [ 0.06093891,  0.01321933, -0.06343992, ..., -0.06490503,\n",
       "          0.15847182,  0.06953354],\n",
       "        [ 0.0537045 ,  0.15235123,  0.11639541, ..., -0.00918345,\n",
       "         -0.09102089, -0.11597849]], dtype=float32)>,\n",
       " <tf.Variable 'dense_17/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_17/gamma:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_17/beta:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_17/moving_mean:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_17/moving_variance:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_18/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[ 0.09260961,  0.08842212,  0.06660549, ...,  0.00509514,\n",
       "         -0.03884691, -0.05292857],\n",
       "        [ 0.06071745,  0.10122392, -0.13499647, ...,  0.00188038,\n",
       "          0.01555805, -0.00441463],\n",
       "        [ 0.0788686 , -0.1644119 ,  0.10309491, ...,  0.07719973,\n",
       "          0.11569268,  0.05940838],\n",
       "        ...,\n",
       "        [-0.1643104 ,  0.11444435, -0.17303589, ..., -0.01733676,\n",
       "         -0.05783515, -0.03080267],\n",
       "        [-0.01347701, -0.13563654,  0.06018977, ...,  0.1700547 ,\n",
       "          0.14757663,  0.14838853],\n",
       "        [-0.12004769,  0.09055775,  0.01617624, ..., -0.01441833,\n",
       "         -0.02964008,  0.07302406]], dtype=float32)>,\n",
       " <tf.Variable 'dense_18/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_18/gamma:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_18/beta:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_18/moving_mean:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_18/moving_variance:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_19/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[-0.01778027, -0.07500533,  0.0960764 , ...,  0.06487621,\n",
       "          0.06572594,  0.01144466],\n",
       "        [ 0.13494542, -0.17204104, -0.06776201, ..., -0.17273134,\n",
       "          0.06286843,  0.15208545],\n",
       "        [ 0.04978715,  0.00977534,  0.16663408, ...,  0.03352106,\n",
       "          0.0518866 , -0.0912146 ],\n",
       "        ...,\n",
       "        [ 0.01934384, -0.01935953, -0.14082617, ..., -0.09025788,\n",
       "          0.13723335,  0.06070253],\n",
       "        [ 0.02841312,  0.11664629,  0.05309685, ...,  0.04146822,\n",
       "          0.06181069,  0.16814756],\n",
       "        [-0.08622167, -0.17216365, -0.11531273, ..., -0.05836646,\n",
       "         -0.159749  ,  0.15832138]], dtype=float32)>,\n",
       " <tf.Variable 'dense_19/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_19/gamma:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_19/beta:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_19/moving_mean:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_19/moving_variance:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_20/kernel:0' shape=(100, 10) dtype=float32, numpy=\n",
       " array([[-1.36787117e-01, -2.23787472e-01,  1.06314480e-01,\n",
       "         -8.19987357e-02,  1.55531973e-01, -2.28097409e-01,\n",
       "         -1.85570002e-01, -7.64648765e-02,  7.92683959e-02,\n",
       "          1.46071464e-01],\n",
       "        [-1.04049310e-01,  1.66504890e-01,  1.19994640e-01,\n",
       "         -1.61027849e-01, -1.29408494e-01,  1.29118413e-02,\n",
       "         -1.09773427e-01, -2.33252004e-01, -1.80936038e-01,\n",
       "         -8.64314586e-02],\n",
       "        [-1.24464385e-01, -1.44352376e-01,  9.21289623e-02,\n",
       "         -1.23752981e-01,  1.89894438e-03,  1.40321344e-01,\n",
       "          1.73804104e-01, -1.95614427e-01, -8.70970339e-02,\n",
       "         -1.00620374e-01],\n",
       "        [ 5.75511754e-02,  2.09693819e-01,  1.45192325e-01,\n",
       "         -2.13503122e-01, -1.30316168e-02,  1.07338727e-02,\n",
       "          1.15147352e-01, -2.31589377e-03, -1.00019336e-01,\n",
       "          1.53958827e-01],\n",
       "        [ 1.72724754e-01, -1.51929140e-01,  8.96862149e-02,\n",
       "          8.57223272e-02, -8.00772905e-02,  2.07737088e-01,\n",
       "         -2.12775007e-01, -8.92133564e-02,  1.87282145e-01,\n",
       "          1.84043527e-01],\n",
       "        [-1.79287225e-01,  1.54325664e-01,  1.94325358e-01,\n",
       "          5.11094332e-02,  5.45942783e-02, -1.99864671e-01,\n",
       "          1.46291465e-01,  3.78708243e-02, -3.40138674e-02,\n",
       "          5.05895615e-02],\n",
       "        [ 9.31459367e-02, -1.61778286e-01,  1.65877581e-01,\n",
       "         -3.84687036e-02, -5.23531586e-02, -1.52472287e-01,\n",
       "          1.02572054e-01,  1.01414293e-01,  1.48385525e-01,\n",
       "         -6.62609339e-02],\n",
       "        [-2.14011997e-01,  1.67624801e-01, -1.97165906e-01,\n",
       "          2.30123490e-01,  1.59802049e-01, -1.47229642e-01,\n",
       "          3.72922421e-02, -1.09447457e-01, -7.42730498e-02,\n",
       "          5.12865484e-02],\n",
       "        [-2.04669073e-01,  1.13900959e-01, -1.64898962e-01,\n",
       "          1.42551810e-02,  2.38010883e-02, -1.49279386e-02,\n",
       "          1.62842482e-01,  1.55019820e-01,  5.62220514e-02,\n",
       "          9.90601480e-02],\n",
       "        [ 6.92997575e-02, -2.20494628e-01, -1.17665082e-02,\n",
       "         -1.80427134e-02, -1.27764970e-01, -2.38856077e-02,\n",
       "          1.76674783e-01, -2.01288968e-01, -1.91692472e-01,\n",
       "          5.91580570e-02],\n",
       "        [ 1.74214602e-01,  1.29139036e-01, -1.21370323e-01,\n",
       "         -1.62062600e-01, -9.52945054e-02, -6.44724071e-02,\n",
       "         -7.95460790e-02,  1.76155984e-01,  6.47576153e-02,\n",
       "         -4.23170924e-02],\n",
       "        [-1.42491758e-02, -1.32405490e-01,  1.91039085e-01,\n",
       "         -7.73972869e-02,  1.99233741e-01, -1.93820387e-01,\n",
       "         -1.64452046e-01,  3.92542183e-02, -3.64487618e-02,\n",
       "         -1.03171915e-01],\n",
       "        [-1.21942632e-01,  6.63520992e-02,  3.48027945e-02,\n",
       "         -2.30354786e-01,  7.42488205e-02,  2.28529334e-01,\n",
       "         -2.09024236e-01, -1.61660284e-01,  9.93277133e-03,\n",
       "         -1.46711528e-01],\n",
       "        [ 1.57511055e-01, -1.86255395e-01,  1.51229382e-01,\n",
       "         -8.50310326e-02, -1.75460607e-01,  1.04910433e-01,\n",
       "          9.29337740e-02,  1.35908216e-01, -6.73954189e-03,\n",
       "         -5.05150706e-02],\n",
       "        [-1.48091942e-01, -3.77053469e-02, -2.30559424e-01,\n",
       "          8.85298550e-02,  1.25020027e-01, -1.56067312e-03,\n",
       "         -2.08685011e-01,  1.07685983e-01, -1.88680097e-01,\n",
       "          2.29507923e-01],\n",
       "        [ 1.23209864e-01,  1.12505496e-01, -2.11309165e-01,\n",
       "         -1.79402992e-01, -1.98686764e-01, -1.99067190e-01,\n",
       "          3.94245386e-02,  8.67756903e-02, -2.01730758e-01,\n",
       "          9.92964208e-02],\n",
       "        [-5.73736131e-02, -1.42340899e-01, -1.08610496e-01,\n",
       "         -2.04936072e-01,  1.66631132e-01,  1.87060803e-01,\n",
       "         -1.53751969e-01, -9.21690911e-02,  4.45094705e-02,\n",
       "         -1.70814067e-01],\n",
       "        [ 2.09600925e-02, -1.30725667e-01,  2.08603740e-02,\n",
       "         -6.32360876e-02,  2.64784694e-02,  1.38230056e-01,\n",
       "          1.01122141e-01, -1.87071875e-01, -7.35141486e-02,\n",
       "          4.11014259e-02],\n",
       "        [-4.21337336e-02,  7.58441389e-02,  1.74053609e-01,\n",
       "          2.82411277e-03, -1.63743049e-02,  1.62835866e-02,\n",
       "         -1.39748424e-01,  2.04303473e-01,  6.40163720e-02,\n",
       "         -5.76833636e-02],\n",
       "        [ 2.13219225e-02, -9.05990750e-02,  1.05835050e-01,\n",
       "          1.80500120e-01, -1.96356282e-01, -8.83446485e-02,\n",
       "         -4.13314551e-02, -1.50375441e-01, -2.79279947e-02,\n",
       "         -1.66014284e-01],\n",
       "        [ 2.25767195e-01, -8.56643766e-02,  1.53806478e-01,\n",
       "          5.63426018e-02,  1.12298697e-01, -2.01877490e-01,\n",
       "         -3.57480496e-02, -2.18595341e-01, -2.19121158e-01,\n",
       "         -1.52779251e-01],\n",
       "        [-5.73644191e-02,  1.04530126e-01,  5.20133674e-02,\n",
       "          2.22060204e-01,  2.12817341e-01, -1.87791407e-01,\n",
       "          1.90758497e-01, -2.23457500e-01, -1.46629006e-01,\n",
       "         -3.62385064e-02],\n",
       "        [ 1.03601277e-01,  8.47439468e-02,  7.70635903e-02,\n",
       "          1.44601047e-01, -7.39636719e-02, -1.49898738e-01,\n",
       "          1.88457966e-03,  1.71072870e-01,  2.06309527e-01,\n",
       "          1.86661452e-01],\n",
       "        [-1.13755397e-01, -6.82692975e-02,  1.17394656e-01,\n",
       "          1.28053129e-03, -1.16267905e-01, -1.37064740e-01,\n",
       "         -1.19952202e-01, -6.77030087e-02, -1.17428169e-01,\n",
       "          2.33252615e-01],\n",
       "        [-1.10992543e-01, -2.06659898e-01, -2.42038220e-02,\n",
       "         -1.81726575e-01, -2.12672278e-01,  1.97486639e-01,\n",
       "         -1.02083385e-03,  1.16452873e-01,  5.50853312e-02,\n",
       "          1.68351829e-01],\n",
       "        [ 2.13208616e-01,  8.47137570e-02, -3.54322791e-02,\n",
       "          1.51630849e-01,  6.80023432e-03,  1.86157972e-01,\n",
       "         -4.62318510e-02, -2.22866148e-01, -2.16818407e-01,\n",
       "         -1.54432595e-01],\n",
       "        [ 9.66247618e-02,  1.84216857e-01, -1.55473024e-01,\n",
       "         -3.79672199e-02,  2.19063252e-01, -1.64824784e-01,\n",
       "         -2.86642760e-02, -6.70552254e-07,  1.79813713e-01,\n",
       "          2.16045678e-02],\n",
       "        [-1.27204627e-01, -1.23419777e-01,  9.43377018e-02,\n",
       "         -1.19642720e-01,  2.32631087e-01, -2.30161235e-01,\n",
       "          3.31020653e-02, -5.11614978e-02,  1.40037090e-01,\n",
       "          2.25353986e-01],\n",
       "        [-1.43910691e-01, -9.71994102e-02,  7.72605240e-02,\n",
       "          1.18064910e-01, -8.83983225e-02, -2.32477292e-01,\n",
       "          5.45347929e-02,  1.64911211e-01, -3.38840187e-02,\n",
       "          1.10991657e-01],\n",
       "        [-1.02010325e-01,  1.67586088e-01, -1.88287646e-01,\n",
       "          1.05801016e-01, -6.01440966e-02, -8.56857002e-02,\n",
       "          1.82895511e-01, -1.84739828e-02, -8.25966448e-02,\n",
       "          1.97207600e-01],\n",
       "        [ 7.49340653e-02,  1.14472985e-01,  1.04449570e-01,\n",
       "          2.64575183e-02,  1.03824139e-01,  2.31139064e-01,\n",
       "         -2.33045429e-01,  1.23785675e-01,  1.26916766e-01,\n",
       "          4.55510914e-02],\n",
       "        [ 1.33598387e-01,  6.94641769e-02, -4.94887382e-02,\n",
       "          1.80473536e-01, -2.04041258e-01,  1.33592755e-01,\n",
       "          2.23669142e-01, -1.86218485e-01,  1.96801573e-01,\n",
       "          1.46741092e-01],\n",
       "        [ 1.69069588e-01,  2.23558664e-01, -1.73152566e-01,\n",
       "         -1.50239632e-01, -9.18346643e-02,  3.91989946e-02,\n",
       "         -1.22018859e-01, -6.06327653e-02,  1.59051895e-01,\n",
       "         -1.34100258e-01],\n",
       "        [ 6.52715564e-02,  6.35005832e-02,  3.34841013e-03,\n",
       "         -2.20254362e-01, -2.00841129e-01,  2.30706543e-01,\n",
       "          1.26745820e-01,  1.60356551e-01,  1.96514577e-01,\n",
       "         -2.37870365e-02],\n",
       "        [-9.30674225e-02,  6.62637353e-02, -1.98227376e-01,\n",
       "         -1.24167927e-01, -2.24048838e-01, -2.08932519e-01,\n",
       "          1.83134556e-01,  8.86853039e-02, -1.41267449e-01,\n",
       "          8.03835988e-02],\n",
       "        [ 9.19209719e-02,  1.17446870e-01, -1.85798362e-01,\n",
       "         -1.77558362e-02, -1.49297535e-01,  4.77909744e-02,\n",
       "         -1.36035115e-01, -1.42345667e-01, -2.21215770e-01,\n",
       "         -1.31565630e-01],\n",
       "        [ 2.30036944e-01, -1.34574279e-01, -1.31562293e-01,\n",
       "          1.92801237e-01,  4.73150611e-02,  6.12145960e-02,\n",
       "         -2.22463846e-01,  1.54488325e-01,  7.21549988e-02,\n",
       "          3.16152871e-02],\n",
       "        [ 2.03645855e-01,  1.00759923e-01,  2.44112313e-02,\n",
       "         -1.71066374e-02,  2.10374147e-01, -2.24576265e-01,\n",
       "         -1.73995882e-01,  1.68726027e-01,  2.21593529e-01,\n",
       "         -2.02748746e-01],\n",
       "        [-1.82586476e-01, -7.27639943e-02, -7.96705782e-02,\n",
       "          3.65423560e-02, -1.89841360e-01,  1.36345267e-01,\n",
       "         -1.23482592e-01,  1.92442179e-01, -2.29136512e-01,\n",
       "         -2.02368498e-01],\n",
       "        [-1.53024435e-01, -4.17591035e-02, -1.52963996e-02,\n",
       "          1.67317420e-01, -2.01461151e-01, -1.12330705e-01,\n",
       "         -1.08072609e-02, -1.37985066e-01,  8.07948709e-02,\n",
       "          1.30162209e-01],\n",
       "        [ 2.05121934e-01, -9.86097306e-02,  2.05961913e-01,\n",
       "          1.65903687e-01, -1.97788879e-01, -6.03894889e-02,\n",
       "          1.49025917e-01,  3.13561559e-02,  4.42382395e-02,\n",
       "          1.37977600e-01],\n",
       "        [-1.34749800e-01, -1.21879987e-01,  1.30598992e-01,\n",
       "          1.65548623e-01,  6.28408492e-02, -4.19937968e-02,\n",
       "         -1.76093668e-01, -2.24316224e-01,  1.74393684e-01,\n",
       "         -2.26619691e-02],\n",
       "        [ 1.31519437e-02,  5.64194322e-02, -2.01295763e-01,\n",
       "          6.46361113e-02, -2.25487396e-01,  1.32569939e-01,\n",
       "          2.09877133e-01, -1.47263169e-01,  2.06216216e-01,\n",
       "         -2.57178992e-02],\n",
       "        [-1.58859730e-01,  2.01206833e-01, -1.56211197e-01,\n",
       "         -2.99149603e-02, -1.22837454e-01,  1.39413148e-01,\n",
       "         -1.09774917e-02, -1.37926310e-01, -1.85391873e-01,\n",
       "         -1.18282840e-01],\n",
       "        [ 1.49218798e-01, -1.19837888e-01, -4.59080935e-03,\n",
       "          1.62743092e-01, -7.30998665e-02, -8.08356255e-02,\n",
       "         -1.40952557e-01, -1.42507941e-01,  4.23295796e-02,\n",
       "         -2.24637300e-01],\n",
       "        [ 6.67535067e-02, -1.75873056e-01,  8.66343677e-02,\n",
       "         -1.45249575e-01, -5.30762523e-02, -1.37862444e-01,\n",
       "         -1.47864491e-01,  1.16557300e-01,  2.09611416e-01,\n",
       "          1.78042948e-02],\n",
       "        [ 1.83173418e-01,  2.06398904e-01,  1.14901364e-03,\n",
       "         -4.43219393e-02, -1.73970431e-01,  1.92220449e-01,\n",
       "         -7.23884106e-02, -2.27498829e-01,  1.88263476e-01,\n",
       "          1.49977535e-01],\n",
       "        [ 1.23282582e-01, -1.93243340e-01, -6.33129328e-02,\n",
       "         -2.26812929e-01, -1.58116817e-01, -6.27342314e-02,\n",
       "         -1.42304361e-01,  6.74194694e-02, -9.30875838e-02,\n",
       "          1.63534850e-01],\n",
       "        [ 5.02178371e-02,  1.79221928e-01, -1.77505434e-01,\n",
       "         -5.29416054e-02, -9.89690572e-02,  9.28643048e-02,\n",
       "          9.57535505e-02,  1.19184017e-01,  9.63209569e-02,\n",
       "          8.96207988e-02],\n",
       "        [ 1.98796004e-01, -9.72746313e-03,  7.66970813e-02,\n",
       "         -9.30645913e-02,  8.87388885e-02,  1.99363083e-01,\n",
       "          1.10362649e-01, -7.35840350e-02,  1.83754355e-01,\n",
       "          8.55005085e-02],\n",
       "        [-7.96229839e-02,  2.00999588e-01, -2.48605460e-02,\n",
       "         -2.04827324e-01, -1.38143152e-01,  1.55799717e-01,\n",
       "          2.13612467e-01, -2.26819783e-01,  2.03071892e-01,\n",
       "          1.85873300e-01],\n",
       "        [-1.51439533e-01,  7.96803236e-02,  6.64696395e-02,\n",
       "         -2.08828598e-02, -2.56377161e-02, -1.53666139e-02,\n",
       "          7.02892244e-02, -9.65641439e-03,  1.37444675e-01,\n",
       "          4.87976670e-02],\n",
       "        [-1.22807883e-01, -1.95148915e-01,  6.13093078e-02,\n",
       "         -6.61585927e-02,  2.17465162e-01,  8.24840069e-02,\n",
       "          2.33048767e-01,  1.37083173e-01,  8.47404301e-02,\n",
       "         -4.28210199e-03],\n",
       "        [ 2.04592466e-01, -1.33285895e-01, -7.81894326e-02,\n",
       "          3.54188085e-02,  1.38150275e-01, -2.03797370e-01,\n",
       "          1.74346834e-01,  2.15981007e-02,  2.30189532e-01,\n",
       "          2.15412974e-01],\n",
       "        [ 1.25598758e-02,  1.75050497e-01,  1.52135670e-01,\n",
       "         -7.96993226e-02,  1.24378592e-01, -2.22136647e-01,\n",
       "          1.66798234e-02, -7.75770843e-02,  1.05003983e-01,\n",
       "          5.65143824e-02],\n",
       "        [-1.55932516e-01, -1.77218556e-01,  1.75101340e-01,\n",
       "         -4.17359322e-02, -4.16167229e-02,  2.19808459e-01,\n",
       "          1.65777564e-01,  1.22172832e-01,  2.30425626e-01,\n",
       "         -5.98788857e-02],\n",
       "        [-1.99864447e-01, -7.79301673e-02,  1.44684017e-01,\n",
       "         -2.05909178e-01,  2.04561114e-01, -2.22497523e-01,\n",
       "          1.64118797e-01,  7.49268234e-02,  2.78831720e-02,\n",
       "          4.86457944e-02],\n",
       "        [-1.36923581e-01,  3.66564989e-02, -1.84773862e-01,\n",
       "         -5.02801538e-02,  1.16630673e-01, -3.87986153e-02,\n",
       "          2.97680795e-02, -8.77567530e-02,  3.10730040e-02,\n",
       "         -7.79010355e-03],\n",
       "        [-1.56717569e-01,  6.52496815e-02, -2.23814026e-01,\n",
       "         -8.22418928e-02, -1.76995724e-01, -1.58534497e-01,\n",
       "          1.70839399e-01, -1.19017795e-01, -1.83542266e-01,\n",
       "         -5.39559126e-03],\n",
       "        [ 4.62542474e-02, -1.47732288e-01,  1.52532130e-01,\n",
       "         -1.27558708e-02,  1.47838324e-01, -1.26822099e-01,\n",
       "         -1.35155767e-01, -1.39222667e-01,  6.54169023e-02,\n",
       "         -1.53016299e-02],\n",
       "        [ 5.04829884e-02, -1.97308183e-01, -3.56632471e-02,\n",
       "         -2.31208399e-01, -1.96425766e-01, -2.20996097e-01,\n",
       "         -5.13890684e-02,  1.66428566e-01,  2.06384063e-02,\n",
       "          3.36102247e-02],\n",
       "        [-3.20102274e-03, -1.10625371e-01,  4.60956991e-02,\n",
       "         -2.11802021e-01,  3.62000763e-02, -2.98770964e-02,\n",
       "          2.04229236e-01, -5.16228825e-02, -1.22696295e-01,\n",
       "          5.82455397e-02],\n",
       "        [ 1.38969630e-01, -5.74783981e-02,  1.96057439e-01,\n",
       "          3.68623137e-02, -9.25765336e-02,  1.41180456e-01,\n",
       "          3.19499969e-02, -8.71451944e-02,  1.37219042e-01,\n",
       "         -1.50048405e-01],\n",
       "        [-5.73985577e-02,  5.10119200e-02,  2.23306358e-01,\n",
       "         -9.99636054e-02, -9.52893794e-02, -1.49222866e-01,\n",
       "         -1.84820071e-01,  3.83544564e-02, -4.64210659e-02,\n",
       "         -1.17351323e-01],\n",
       "        [ 2.15122998e-02,  2.18332201e-01, -1.98359400e-01,\n",
       "         -1.12659954e-01,  1.58208132e-01, -1.13518134e-01,\n",
       "          6.75436854e-02, -7.76439011e-02,  4.15026844e-02,\n",
       "         -2.04599410e-01],\n",
       "        [ 9.38332975e-02,  1.13766789e-02, -1.66738778e-01,\n",
       "          2.17668712e-03, -1.01517320e-01, -1.43631279e-01,\n",
       "         -1.44226253e-01,  2.08742857e-01, -1.81558743e-01,\n",
       "          1.19140565e-01],\n",
       "        [-3.82292122e-02,  1.48445874e-01,  3.17443609e-02,\n",
       "          1.37040079e-01, -1.44844770e-01, -1.78366512e-01,\n",
       "          1.17400944e-01, -1.32115722e-01, -1.06974542e-01,\n",
       "         -1.35597393e-01],\n",
       "        [ 1.42257869e-01,  1.54488891e-01, -2.01912120e-01,\n",
       "          2.09951788e-01,  5.49305379e-02,  2.92143822e-02,\n",
       "          2.09605783e-01, -2.06624478e-01,  2.04931557e-01,\n",
       "          1.12623036e-01],\n",
       "        [ 7.46612549e-02, -6.13141507e-02,  2.31680632e-01,\n",
       "          1.16768539e-01, -4.69304621e-03,  1.34929806e-01,\n",
       "          1.48888499e-01, -2.01564327e-01,  1.43537074e-01,\n",
       "         -1.49791598e-01],\n",
       "        [ 1.68238789e-01,  3.15567255e-02, -1.02424264e-01,\n",
       "         -8.93950462e-03,  9.54920650e-02,  1.13721162e-01,\n",
       "          4.80306149e-02, -2.05561221e-02,  4.04719412e-02,\n",
       "         -9.46725905e-02],\n",
       "        [ 8.89807940e-03,  1.33199990e-01, -1.87215313e-01,\n",
       "         -7.28988051e-02,  4.94147837e-02, -4.94574308e-02,\n",
       "         -3.41428965e-02, -1.44504368e-01,  1.78097904e-01,\n",
       "         -1.95672557e-01],\n",
       "        [ 2.29212165e-01,  1.52703851e-01, -1.75800771e-01,\n",
       "         -1.71193480e-01, -1.60953850e-02, -1.20677076e-01,\n",
       "         -6.14578724e-02, -7.73750097e-02,  6.27276599e-02,\n",
       "         -1.30350858e-01],\n",
       "        [ 7.23742247e-02,  2.07996994e-01, -2.05714792e-01,\n",
       "          5.29563129e-02,  1.58554256e-01,  5.59728146e-02,\n",
       "         -6.89339191e-02, -1.23134404e-01, -1.74089596e-01,\n",
       "          1.53621346e-01],\n",
       "        [ 8.50090384e-02,  6.98526800e-02,  2.55528092e-03,\n",
       "          2.29804039e-01, -1.46207094e-01,  1.50352716e-05,\n",
       "         -1.41157463e-01, -1.57332987e-01, -3.62037569e-02,\n",
       "          8.13411772e-02],\n",
       "        [-2.18738779e-01,  5.25722802e-02, -5.02817631e-02,\n",
       "         -1.67186067e-01, -9.13495123e-02, -1.60941154e-01,\n",
       "          2.00496793e-01, -2.04961300e-01,  8.29393268e-02,\n",
       "         -7.16253966e-02],\n",
       "        [-2.09519148e-01,  2.07933873e-01, -1.01357788e-01,\n",
       "          1.47329092e-01,  2.25284427e-01,  8.36536288e-02,\n",
       "          1.35848254e-01,  1.83454454e-01,  9.13417637e-02,\n",
       "          1.72908247e-01],\n",
       "        [ 2.25031525e-01, -3.26541662e-02, -6.04439974e-02,\n",
       "          1.26732439e-02, -2.62525529e-02,  1.42429322e-02,\n",
       "         -6.39692098e-02, -2.13893339e-01,  1.65914565e-01,\n",
       "          2.06931561e-01],\n",
       "        [ 9.94336009e-02,  1.28440946e-01, -6.46831095e-03,\n",
       "          1.88920051e-01, -9.19708610e-02, -2.30348378e-01,\n",
       "          4.68507409e-03, -3.95015031e-02,  2.31223047e-01,\n",
       "          1.31664038e-01],\n",
       "        [ 5.55434227e-02, -2.45278925e-02,  1.77506655e-01,\n",
       "          2.12557852e-01, -6.45683557e-02,  1.68599844e-01,\n",
       "         -1.37954831e-01, -6.59108162e-04, -5.17189801e-02,\n",
       "         -6.61853254e-02],\n",
       "        [-1.63265765e-02,  1.54458195e-01, -7.73151517e-02,\n",
       "          1.30878806e-01, -1.95354491e-01,  9.93207395e-02,\n",
       "         -6.07449114e-02,  2.12878913e-01,  6.58228993e-04,\n",
       "          1.42642289e-01],\n",
       "        [-7.68741965e-03, -1.87462777e-01, -1.14201695e-01,\n",
       "         -1.72221944e-01,  1.48816377e-01,  1.03465021e-01,\n",
       "         -2.18449071e-01, -2.05004126e-01, -8.29958916e-02,\n",
       "          9.31789577e-02],\n",
       "        [ 3.26617062e-03,  4.77136374e-02,  1.82930082e-01,\n",
       "          1.21436298e-01,  2.07649827e-01, -1.75607666e-01,\n",
       "         -2.50131190e-02,  1.22217983e-01,  1.45658344e-01,\n",
       "          1.73060894e-02],\n",
       "        [-1.89179927e-02,  2.13519424e-01, -4.79929894e-02,\n",
       "          2.10130870e-01,  1.04638606e-01, -2.12504953e-01,\n",
       "         -7.03970343e-02, -1.86445862e-02, -5.15684187e-02,\n",
       "          1.40184343e-01],\n",
       "        [ 1.40543282e-01,  1.91735804e-01, -1.50247991e-01,\n",
       "          2.14570165e-01, -1.71819195e-01,  1.92595154e-01,\n",
       "         -1.96344748e-01,  1.26663119e-01,  1.68847084e-01,\n",
       "          1.66611135e-01],\n",
       "        [-4.17244136e-02, -5.83943278e-02, -2.70083547e-03,\n",
       "         -7.51735419e-02, -7.05721080e-02,  9.18220282e-02,\n",
       "         -1.30553335e-01, -2.28641272e-01,  1.47378713e-01,\n",
       "          1.79819345e-01],\n",
       "        [-9.91521329e-02,  1.23015344e-01,  1.33732647e-01,\n",
       "         -1.92389503e-01,  1.19651258e-02,  2.15459526e-01,\n",
       "         -1.26404032e-01, -6.30897582e-02,  1.62450880e-01,\n",
       "         -2.17269763e-01],\n",
       "        [ 3.91593575e-03,  3.24733555e-02, -4.19755429e-02,\n",
       "          5.79429567e-02, -8.30779672e-02,  2.18798101e-01,\n",
       "          1.78599536e-01,  2.11632729e-01,  1.84920907e-01,\n",
       "          3.08650732e-02],\n",
       "        [ 2.03870028e-01, -1.25540346e-01, -1.87206954e-01,\n",
       "          1.76694423e-01,  2.13693708e-01,  1.48453176e-01,\n",
       "         -1.84875637e-01,  7.24688768e-02,  2.27400362e-02,\n",
       "         -1.07145652e-01],\n",
       "        [ 6.93754852e-02, -6.53012097e-03,  1.37136638e-01,\n",
       "          2.22859144e-01,  1.84304744e-01,  7.41335750e-03,\n",
       "          2.06725866e-01, -1.86042309e-01,  9.38532650e-02,\n",
       "         -3.94859612e-02],\n",
       "        [ 9.80329216e-02,  6.69543445e-03, -1.05960056e-01,\n",
       "         -2.31927767e-01, -2.25033700e-01,  1.99418366e-02,\n",
       "         -1.07829541e-01, -2.02172935e-01, -7.75050968e-02,\n",
       "          3.34873796e-04],\n",
       "        [ 1.39884114e-01, -1.76469982e-03,  1.55413002e-01,\n",
       "         -4.33700532e-02,  6.31417036e-02, -1.64261401e-01,\n",
       "          9.87480581e-03, -2.17020810e-01, -2.30087176e-01,\n",
       "         -2.00518548e-01],\n",
       "        [ 1.72322512e-01,  2.33430177e-01, -9.55088288e-02,\n",
       "          7.21166730e-02,  1.17778242e-01,  1.09080076e-01,\n",
       "          6.95221424e-02,  6.59806430e-02, -1.71149999e-01,\n",
       "         -1.18096247e-01],\n",
       "        [-8.55126381e-02,  6.76681995e-02, -3.13743949e-03,\n",
       "          8.59639049e-03,  1.75040156e-01, -1.95268244e-01,\n",
       "         -1.97153434e-01, -2.29567483e-01,  1.82264358e-01,\n",
       "          3.30234468e-02],\n",
       "        [ 3.08795571e-02,  8.75289440e-02, -1.20779864e-01,\n",
       "         -1.13189943e-01, -1.67283177e-01, -1.03181392e-01,\n",
       "         -1.67803079e-01, -1.16065226e-01,  1.23565793e-01,\n",
       "          1.22555196e-01],\n",
       "        [-1.56147331e-02, -8.81080031e-02,  1.75608993e-02,\n",
       "         -6.33077621e-02,  4.37701344e-02,  1.62740082e-01,\n",
       "          1.46753222e-01,  9.12029445e-02, -3.39068025e-02,\n",
       "          2.85095274e-02],\n",
       "        [-1.68080181e-02,  1.33501291e-01, -1.42908245e-02,\n",
       "         -2.95203477e-02, -2.03450292e-01,  4.22090292e-03,\n",
       "         -1.02709815e-01,  1.34456843e-01,  2.08233833e-01,\n",
       "         -1.41231120e-02],\n",
       "        [-2.31829032e-01,  1.65624171e-01, -1.88911915e-01,\n",
       "         -1.75631493e-01,  6.32694960e-02,  2.23365843e-01,\n",
       "         -1.00615472e-01, -1.14634901e-01, -8.75806361e-02,\n",
       "         -1.16894394e-02],\n",
       "        [ 1.96038097e-01,  1.59174114e-01, -7.81726688e-02,\n",
       "         -1.92990378e-01, -1.76756456e-01, -1.40183136e-01,\n",
       "          1.92644924e-01,  9.50539708e-02,  1.64612412e-01,\n",
       "         -1.06168538e-01],\n",
       "        [-7.37312585e-02, -1.85775980e-01,  2.19811559e-01,\n",
       "         -1.15279935e-01, -7.94266909e-02,  2.54359245e-02,\n",
       "          9.26858187e-03, -4.95341122e-02,  2.44427025e-02,\n",
       "         -1.66601732e-01],\n",
       "        [-1.07006729e-01, -3.62999290e-02, -2.79066563e-02,\n",
       "          1.89450651e-01, -1.37816459e-01, -2.60505974e-02,\n",
       "          1.73747152e-01, -1.17695555e-01,  6.04995191e-02,\n",
       "          1.63388252e-02]], dtype=float32)>,\n",
       " <tf.Variable 'dense_20/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 1.7775 - accuracy: 0.4070 - val_loss: 0.9746 - val_accuracy: 0.6638\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 20s 12ms/step - loss: 1.0747 - accuracy: 0.6220 - val_loss: 0.7967 - val_accuracy: 0.7128\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.9527 - accuracy: 0.6643 - val_loss: 0.7130 - val_accuracy: 0.7426\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.8702 - accuracy: 0.6927 - val_loss: 0.6520 - val_accuracy: 0.7698\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.8263 - accuracy: 0.7077 - val_loss: 0.6133 - val_accuracy: 0.7804\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 16s 10ms/step - loss: 0.7833 - accuracy: 0.7241 - val_loss: 0.5918 - val_accuracy: 0.7978\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 0.7550 - accuracy: 0.7351 - val_loss: 0.5617 - val_accuracy: 0.8060\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 0.7304 - accuracy: 0.7438 - val_loss: 0.5494 - val_accuracy: 0.8056\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.7103 - accuracy: 0.7504 - val_loss: 0.5342 - val_accuracy: 0.8154\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 16s 10ms/step - loss: 0.6820 - accuracy: 0.7600 - val_loss: 0.5224 - val_accuracy: 0.8204\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 0.6653 - accuracy: 0.7677 - val_loss: 0.5113 - val_accuracy: 0.8218\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.6524 - accuracy: 0.7721 - val_loss: 0.4986 - val_accuracy: 0.8288\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 16s 10ms/step - loss: 0.6329 - accuracy: 0.7762 - val_loss: 0.4895 - val_accuracy: 0.8326\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.6250 - accuracy: 0.7814 - val_loss: 0.4787 - val_accuracy: 0.8320\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.6074 - accuracy: 0.7869 - val_loss: 0.4691 - val_accuracy: 0.8392\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.5958 - accuracy: 0.7907 - val_loss: 0.4611 - val_accuracy: 0.8370\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.5858 - accuracy: 0.7952 - val_loss: 0.4541 - val_accuracy: 0.8424\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.5757 - accuracy: 0.7974 - val_loss: 0.4488 - val_accuracy: 0.8416\n",
      "Epoch 19/100\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.5657 - accuracy: 0.7999 - val_loss: 0.4442 - val_accuracy: 0.8446\n",
      "Epoch 20/100\n",
      "1719/1719 [==============================] - 18s 11ms/step - loss: 0.5574 - accuracy: 0.8040 - val_loss: 0.4412 - val_accuracy: 0.8448\n",
      "Epoch 21/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.5505 - accuracy: 0.8072 - val_loss: 0.4275 - val_accuracy: 0.8490\n",
      "Epoch 22/100\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.5393 - accuracy: 0.8121 - val_loss: 0.4216 - val_accuracy: 0.8518\n",
      "Epoch 23/100\n",
      "1719/1719 [==============================] - 18s 11ms/step - loss: 0.5281 - accuracy: 0.8162 - val_loss: 0.4179 - val_accuracy: 0.8510\n",
      "Epoch 24/100\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.5201 - accuracy: 0.8184 - val_loss: 0.4157 - val_accuracy: 0.8532\n",
      "Epoch 25/100\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.5161 - accuracy: 0.8204 - val_loss: 0.4093 - val_accuracy: 0.8570\n",
      "Epoch 26/100\n",
      "1719/1719 [==============================] - 16s 10ms/step - loss: 0.5076 - accuracy: 0.8220 - val_loss: 0.4097 - val_accuracy: 0.8558\n",
      "Epoch 27/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.5019 - accuracy: 0.8234 - val_loss: 0.4020 - val_accuracy: 0.8536\n",
      "Epoch 28/100\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 0.4899 - accuracy: 0.8288 - val_loss: 0.3979 - val_accuracy: 0.8608\n",
      "Epoch 29/100\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 0.4910 - accuracy: 0.8286 - val_loss: 0.3921 - val_accuracy: 0.8618\n",
      "Epoch 30/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 0.4863 - accuracy: 0.8296 - val_loss: 0.3942 - val_accuracy: 0.8618\n",
      "Epoch 31/100\n",
      "1719/1719 [==============================] - 16s 10ms/step - loss: 0.4728 - accuracy: 0.8333 - val_loss: 0.3842 - val_accuracy: 0.8614\n",
      "Epoch 32/100\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.4713 - accuracy: 0.8347 - val_loss: 0.3835 - val_accuracy: 0.8632\n",
      "Epoch 33/100\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.4716 - accuracy: 0.8363 - val_loss: 0.3822 - val_accuracy: 0.8662\n",
      "Epoch 34/100\n",
      "1719/1719 [==============================] - 18s 11ms/step - loss: 0.4612 - accuracy: 0.8396 - val_loss: 0.3789 - val_accuracy: 0.8688\n",
      "Epoch 35/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 0.4548 - accuracy: 0.8391 - val_loss: 0.3803 - val_accuracy: 0.8666\n",
      "Epoch 36/100\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 0.4500 - accuracy: 0.8434 - val_loss: 0.3767 - val_accuracy: 0.8676\n",
      "Epoch 37/100\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 0.4437 - accuracy: 0.8441 - val_loss: 0.3714 - val_accuracy: 0.8696\n",
      "Epoch 38/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.4437 - accuracy: 0.8450 - val_loss: 0.3762 - val_accuracy: 0.8646\n",
      "Epoch 39/100\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 0.4396 - accuracy: 0.8470 - val_loss: 0.3733 - val_accuracy: 0.8678\n",
      "Epoch 40/100\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 0.4342 - accuracy: 0.8493 - val_loss: 0.3710 - val_accuracy: 0.8690\n",
      "Epoch 41/100\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 0.4324 - accuracy: 0.8471 - val_loss: 0.3739 - val_accuracy: 0.8634\n",
      "Epoch 42/100\n",
      "1719/1719 [==============================] - 20s 12ms/step - loss: 0.4302 - accuracy: 0.8491 - val_loss: 0.3668 - val_accuracy: 0.8682\n",
      "Epoch 43/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.4262 - accuracy: 0.8529 - val_loss: 0.3593 - val_accuracy: 0.8748\n",
      "Epoch 44/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.4200 - accuracy: 0.8523 - val_loss: 0.3637 - val_accuracy: 0.8720\n",
      "Epoch 45/100\n",
      "1719/1719 [==============================] - 18s 11ms/step - loss: 0.4193 - accuracy: 0.8543 - val_loss: 0.3654 - val_accuracy: 0.8720\n",
      "Epoch 46/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.4186 - accuracy: 0.8530 - val_loss: 0.3579 - val_accuracy: 0.8780\n",
      "Epoch 47/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.4117 - accuracy: 0.8558 - val_loss: 0.3601 - val_accuracy: 0.8712\n",
      "Epoch 48/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.4086 - accuracy: 0.8570 - val_loss: 0.3577 - val_accuracy: 0.8748\n",
      "Epoch 49/100\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.4114 - accuracy: 0.8557 - val_loss: 0.3617 - val_accuracy: 0.8700\n",
      "Epoch 50/100\n",
      "1719/1719 [==============================] - 20s 12ms/step - loss: 0.4049 - accuracy: 0.8577 - val_loss: 0.3543 - val_accuracy: 0.8732\n",
      "Epoch 51/100\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.4013 - accuracy: 0.8585 - val_loss: 0.3559 - val_accuracy: 0.8720\n",
      "Epoch 52/100\n",
      "1719/1719 [==============================] - 18s 11ms/step - loss: 0.4003 - accuracy: 0.8596 - val_loss: 0.3576 - val_accuracy: 0.8704\n",
      "Epoch 53/100\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.3954 - accuracy: 0.8613 - val_loss: 0.3536 - val_accuracy: 0.8712\n",
      "Epoch 54/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.3956 - accuracy: 0.8630 - val_loss: 0.3501 - val_accuracy: 0.8744\n",
      "Epoch 55/100\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.3901 - accuracy: 0.8644 - val_loss: 0.3459 - val_accuracy: 0.8750\n",
      "Epoch 56/100\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.3867 - accuracy: 0.8650 - val_loss: 0.3443 - val_accuracy: 0.8748\n",
      "Epoch 57/100\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.3816 - accuracy: 0.8653 - val_loss: 0.3420 - val_accuracy: 0.8732\n",
      "Epoch 58/100\n",
      "1719/1719 [==============================] - 18s 11ms/step - loss: 0.3813 - accuracy: 0.8660 - val_loss: 0.3446 - val_accuracy: 0.8748\n",
      "Epoch 59/100\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 0.3787 - accuracy: 0.8645 - val_loss: 0.3431 - val_accuracy: 0.8782\n",
      "Epoch 60/100\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.3752 - accuracy: 0.8684 - val_loss: 0.3432 - val_accuracy: 0.8752\n",
      "Epoch 61/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.3761 - accuracy: 0.8678 - val_loss: 0.3386 - val_accuracy: 0.8794\n",
      "Epoch 62/100\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 0.3706 - accuracy: 0.8684 - val_loss: 0.3379 - val_accuracy: 0.8774\n",
      "Epoch 63/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 0.3732 - accuracy: 0.8687 - val_loss: 0.3373 - val_accuracy: 0.8788\n",
      "Epoch 64/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 0.3673 - accuracy: 0.8711 - val_loss: 0.3405 - val_accuracy: 0.8780\n",
      "Epoch 65/100\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.3651 - accuracy: 0.8728 - val_loss: 0.3372 - val_accuracy: 0.8766\n",
      "Epoch 66/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.3684 - accuracy: 0.8715 - val_loss: 0.3346 - val_accuracy: 0.8792\n",
      "Epoch 67/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.3621 - accuracy: 0.8732 - val_loss: 0.3330 - val_accuracy: 0.8798\n",
      "Epoch 68/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 0.3601 - accuracy: 0.8720 - val_loss: 0.3327 - val_accuracy: 0.8802\n",
      "Epoch 69/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.3585 - accuracy: 0.8732 - val_loss: 0.3389 - val_accuracy: 0.8774\n",
      "Epoch 70/100\n",
      "1719/1719 [==============================] - 20s 11ms/step - loss: 0.3593 - accuracy: 0.8732 - val_loss: 0.3346 - val_accuracy: 0.8772\n",
      "Epoch 71/100\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.3530 - accuracy: 0.8759 - val_loss: 0.3266 - val_accuracy: 0.8798\n",
      "Epoch 72/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.3525 - accuracy: 0.8762 - val_loss: 0.3274 - val_accuracy: 0.8830\n",
      "Epoch 73/100\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.3541 - accuracy: 0.8754 - val_loss: 0.3328 - val_accuracy: 0.8812\n",
      "Epoch 74/100\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 0.3479 - accuracy: 0.8777 - val_loss: 0.3292 - val_accuracy: 0.8818\n",
      "Epoch 75/100\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 0.3478 - accuracy: 0.8767 - val_loss: 0.3326 - val_accuracy: 0.8788\n",
      "Epoch 76/100\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 0.3474 - accuracy: 0.8775 - val_loss: 0.3291 - val_accuracy: 0.8804\n"
     ]
    }
   ],
   "source": [
    "# Tensorboard, earlystopping, ModelCheckpoint\n",
    "logdir = './dnn-bn-callbacks'\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "output_model_file = os.path.join(logdir,\n",
    "                                 \"fashion_mnist_model.h5\")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(logdir),\n",
    "    keras.callbacks.ModelCheckpoint(output_model_file,\n",
    "                                    save_best_only = True),\n",
    "    keras.callbacks.EarlyStopping(patience=5, min_delta=1e-3),\n",
    "]\n",
    "history = model.fit(x_train_scaled, y_train, epochs=100,\n",
    "                    validation_data=(x_valid_scaled, y_valid),\n",
    "                    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEzCAYAAAACSWsXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3xV9f3H8df3nDtzs/dOSCCMsDcIyhRqVdzVtlpbFa3a1rZq7frVVttqW7WttlacbbWCo1ZEFEUBAdl7yUxCEkhC9ry56/z+OGHISoCEJJfP8/E4j5Pce+6535PAfef7Pd+hDMNACCGEEJ1H6+wCCCGEEBc6CWMhhBCik0kYCyGEEJ1MwlgIIYToZBLGQgghRCeTMBZCCCE6WathrJR6SSlVppTaeornlVLqr0qpPUqpzUqpoe1fTCGEECJ4taVm/Aow/TTPfwXo1bLNBJ4992IJIYQQF45Ww9gwjM+AytMcMgP4l2FaCUQqpZLaq4BCCCFEsGuPe8YpQOEx3xe1PCaEEEKINrCczzdTSs3EbMrG6XQOS0tLa7dzBwIBNO3Uf1tUNBk0+AzSw7pXn7XWrqs7C9Zrk+vqXuS6upfufF27du0qNwwj7qRPGobR6gZkAltP8dxzwE3HfL8TSGrtnMOGDTPa06JFi077/EvL9hkZP5lnlNW62/V9O1pr19WdBeu1yXV1L3Jd3Ut3vi5grXGKTGyPPy/mAre09KoeDdQYhnGwHc7brnrFhwGwu6yuk0sihBBCfFmrzdRKqdeBCUCsUqoI+BVgBTAM4x/AfOAyYA/QCHy7owp7LnolhAKwp6yesdmxnVwaIYQQ4qhWw9gwjJtaed4A7mm3EnWQ+DA7YXYLe8rqO7soQgghxJd0z7vgZ0EpRc+EUHaXShgLIYToWoIijBfkL+Dh4oepdlef9rhe8aHslpqxEEKILiYowlhTGhW+CkoaS057XK/4MMrrm6lu9JynkgkhhBCtC4owTgxJBKC0ofS0x/U8phOXEEII0VUERRgnuBIAKGk4fc24Z5wZxtJULYQQoisJijCOccSgobXaTJ0S6cRp1aUTlxBCiC4lKMJY13Qi9chWm6k1TdEzPlQm/hBCCNGlBEUYA0RaIlutGUNLj2qpGQshhOhCgieM21AzBuifEkFJrZsD1U3noVRCCCFE64ImjKMsUZQ2lh5erOKURvaIBmBN/umWaBZCCCHOn6AJ40g9kmZ/M1XNVac9rm9SOGF2C6vyJIyFEEJ0DUETxlGWKKD1sca6phieGcUaCWMhhBBdRPCEsW6GcWtjjQFG9Ihmd1k9FfXNHV0sIYQQolVBE8aRlkiANvWoHnXkvvHpm7SFEEKI8yFowjhUC8WiWdrUo3pASiR2i8ZqaaoWQgjRBQRNGGtKIyEkoU01Y5tFY2h6FKvzK85DyYQQQojTC5owBswwbsM9YzCHOG0/UEud29vBpRJCCCFOL6jCONGV2KZmajDDOGDAugK5byyEEKJzBVUYJ7gSKG0sJWAEWj12SHokFk3JfWMhhBCdLqjCODEkEW/AS6W79YANsVkYkBohYSyEEKLTBVcYuxIBKG1se1P1pqJq3F5/RxZLCCGEOK2gCuMEVwLQtok/wBxv7PUbbCys7shiCSGEEKcVVGGcGGLWjNsaxsMyolEKaaoWQgjRqYIqjKMd0Vg1a5ubqSOcVvokhksYCyGE6FRBFcZKqTMaawxmU/W6giq8/tZ7YAshhBAdIajCGM5srDGYnbiavH62Ftd0YKmEEEKIU7N0dgHaW6IrkQ1lG9p8/IhMc9GI1XmVDEmP6qhiCSFE0DMMA7xeAh4vhqcZw+sDnxfD68Xw+TB8PvTISCzx8SjtzOuChteLXlJC3cKFNO/dR/PePXj27sNbVIQWFoYlJgY9NhZLTAyW2BiUzYbh8RBobsZo9mB4PADY0tOwZWZi69EDa1oams125D0Czc34KyvxVVZiNDURMnx4u/18Tifowjgh5OjEH5pq/ZcdF2YnK9bFmvxK7rwk+zyUUAhxMkYggHvzZuqXLkOPiSZ82jQsMTGdXaxOFXC7ad67l+bdu2nevZtAbR22jHRsPXqYW2oqymYj0NBA07ZtuLdsoWnzFpq2bCauuoZ9KclY4uKwxMVjiY9Hj4wk0FCPv6YWf03NkQ1AczhQTgeaMwTN4UALCUGPjECPiECLMPd6WBi+8gq8RYV4iorwFhbhLSrCV1WF0dxshp1htHpdym7HmpaKLT0DW3o61qREsFhQug5KA02hlMJ36BCelvfwFhXhLSkhNhCgqOU8loR47JnpOKZcQqDJjb+yBm9hIU0bN+KvrDTLohTKZkVZdJRFgd+P/9jlczWFNT4GDANfTR2G23P0qRA7vddvbM9f6SkFXRgnuhLxBXxUuiuJdca26TUje0Qzf8tBAgEDTVMdXEIhgpOvqoq6jz+mYdlytPCwIx+0tox0rGnp6KGuE14TaGig/vPPqV+0mPolS/BXVIBSYBiUPvpbQkaNJPyyywifOhU9MhLD58NTUEDzzp24d+7Cs28f1tRUQkYMJ2ToUPTIyBPew/D7zQ/y4mKUw4EeFoYWFoYeFoYKCTnj6ww0NtK8Lw/Pvr00792Hr7QUw9NMoKXmZTQ3Y3i95nVoCqXpoGkoTUNzhaBHRqFHRaFHR2GJikJzucxQrKrCV1nVsq/Ak5+Pd3/hkXBTVitaWJgZMofpOpa4OHxlZRAw+71Y09IIGTyE2oZ6Imw2vGVlNOetxnfoEPh8oBR6eDhaZAR6RCR6eDgoRaCpkUB5Bd6mIgLuJgL1DQTq6k4ZrnpEBNbUVOx9++KKiUE57ChdQ1M+lPKi8KLsIShnqLk5wsDhwl9ZiSdvD56CfLx5u2lYthTDc+o1AvRwB7YIHWe4l4hYN1ZnA/ZwH7ZwH7r1ANASllYgHOihgTUEQ3eCux4CTajjPtb9HoWnznLM1gAKLJEBdFsA3RFAtwewuBxn/O/jbAVdGCeEHB1rfCZhPHtNITtL6+ibFN6RxRPitAKNjaBpaI4z+xAINDTgLSvDV3YIpWs4BgxAs9vb/HrDMDCam/HX1oJhmM2Ix3+CnYSvspK6jxdSt+BDGlatBr8fS1IShteLv7z8S8cqu53jPxUNrxf8frSwMELHjyd00iRCx4/DW1pK7QcfUDt/PiW//D9Kfv0b7D0y8RTsP9LUiMWCLSWF+sWLqXz5ZQDsOTmEDB+GHh1zJCw9eXlHX3M8XSfO6WRvQgJ6VCSWqGj0qCi00FCM5mYCTU0Y7iYCTW4CjY14CvfjO3Dw6OstFixxcWh2O+rwZrOiHC0/+4ABfj9Gy+Y7dAhf9Ub8VdVmMB5H2e3o0dHoUZE4+vQl4oorsffqhb1XL2zpaSiLBX9tLZ78fDx5eTTn5+MtLsaWlo5z4AAcAwdiiTJvt+1evJhhEyYc/VkHAgQaG9GcTvPXEPBDwAeGH+rLoKYQqguP7muLMeo0AtXl+Kur8Tcb+D0aFocfq8uPbi8B+0Fw7DLfoLECGupP/w9GaXB4uuIkczMMMxwxFBgt2W8oDAMsDj+a3QaRGRCdA1GZ7DvUSFbPHNAsoHTQWmrTfg94G8HbBN4mlKcBrCEQmQYRqS1bGjij0X1unM11OJvroLkWPPXm+awhYHMd3dtO/AOyowRdGB+ehaukoYT+sf3b9Jox2TEoBe9tOiBhLDqUYRj4Kyrw5OXhKSgwm+AKC/EUF+EtKjZrhmDeV0tMxJqYiCUxAT0qCqOxiUBjA4GGBvwNLfuKSnxlZQQaGr70Pspmwzl4MCGjRuIaORLHwIH4KyvNcDocUnv34j1URqCuHn9dHXiP1k6saWmEjh+Ha9x4XKNGornMDyV/TQ2N69fTuHYtTWvX0bR1K/j9WDPSibntNsKnT8Pety9KKfz1DXgL9+Mp2I+noAB/7YmdJJXNhmvUaEKGDUVZrUce1yMicOTkEPf97+Pevp3a+fNp3r0b17jx2Hvn4OjTB1tWFprNRqC5GfeWLTSuXUvjmrXU/O9dAk1NWFNSsGVn4Ro7Fnt2Fta0dPP+YX0d/ro6AnV1+GvrKNyxnQhniPnzyduHf301gfp6lMOB5nS2NN860ZxOQoYOw359FrasbOw9s7GlpaGOud94Sn4f+NxmYBgBDL+XQG0t/soK/PV16CE2LC4rSg+g/M1moFid4IyGkChwRoGug68ZvX4vTu9mnJbN4NoMkTugzoBVdlhrB4u5jWhohE3ma/C5Ub5mdH+zGcCnpSAsCSJSUDE90NNHoLviIDTeLI+/GZqqwV0D7pa9YYArFkJiwBVnfu2IMK+juRbctUf3mg72cHCEgyMCZQ/HYnOZgXpCORLMsmj6kUf3L15M1kUTWv+Zn44txNzCEs7tPO0oaMO4rWONAZIinFzaL4HXVu3nnok9cdmD7scizpDh8bQEXiOBxgbwn2TKVKVQum6GiMWKspr3vPSSEhpWr8ZfXo6vvAJfRQXegwfw5OXjyc83m/4Os1iwJiVhS0vFMWkS1tRUMAy8pSX4DpbgLS2ladMm/NXVZo3GFYIe4kJzmZu9d29c48dhjY837w3GxxNoaqJx9RoaV6+m/Jm/UW48c0LRtYgI7FlZOHNz0cLC0cPD0ELD0MPDMLxeGlaspPqd/1H1n9fBaiVk8GCiDxxg14ED5gev1YpzwABiZt5B+KWXYu/T54SatB7qQu/bF0ffvmf9e1BK4czNxZmbe8pjNLudkOHDzY42d3Gko1BbWxe2H1eDPCVvEzQcatnKoXYFrJ5r1gibqsyAaqo6+rWv6UgQctziNQrQW7Y2Uy1HGy3/Fm1hkDQQBt0Ius0MSZ8bfB7wuWk0DuFKSmsJZ4e5122gW1tqlNrR2mVITEsNMg3CU8DShj8wRLsKutSJtEdi1+1nNNYYYObF2SzYVsqbawu59aIeHVQ60RUZgQCNq1dTM/c96pd+RqC6xmw+PUuxwP5jH9D1lo4mmURccYXZ8SYzE1uPTKyJiShL6/8NDcNoU7PxYWGTJgEtNdl163Bv3YoeG4s9uyf27Cz0mJjTni/6llsIeDw0rV9P/dKlNKxYQSA8nNhrryFk+HCcAweecVP6+aIslhN/poZhhqSnoaUZs2XvaSSubBWs399Se2tptnTXmIHbWN4SvhXma07G4jBrjM6WGmx0FjgizZrtkSB0mAGn21oCsCUINd3cWxxm06jVAZaW13mbWoK9EhorzT0KEvtD4kCI6mEG6ilsW7yYCW35I0N0CUEXxmcz8QfAsIwohmVE8eLyPL45OgOLHnRDsIOO4fHQvGcP7h07cO/4AveOHfhKS9FCQ7/USUcLD8cSF4c1MeFo029CAp6CAmrnzqVm3vv4SkrQXC5CJ03CmpiAFhJypPapuVwnDUwjEDDvB/p8GJ6WoRt+H7uKihgwfjyW2Fj02Fj0iIizGsZxrDMJ4mPpERGETZp0JJzPhGaz4Ro9Gtfo0QAsXryYwe314W4YZuA1VZo1PEfEibWx5nqoyoPKPKjcB7XFLU2jxzR5eurM8HJGmgHojDTPZRhQdxDqSsytvsRsIj6JXIDtxzxgCzObUENizObW6OyWptfDTbBxR5tiXXHn9b6iCF5BF8bQMvHHGTRTH3bH+CzuenUdH24r4fKByR1QMnE8w+fDW1KCp6AA7/79BBqb0EKcKIcTzelAORwoXcdXdghvyUF8JaUtTbgHac4vOHKfU4WE4OjdG+fgwQQazF6g3uJimuvq8NfWEqg/RccSi4XQceOIePABQidNapfannvxYlxjxpzzeboNvxcOfQElW+DgZji0w2yWPdw0enjvdbeE4wFz72388nkOh6o93KwRNpR9+Xl7BDgjzL0j3OyQYw81a5DuGqgtgtJt5n1MFIQlmlvGGHMfmgC20JYOOs6WmmgIazbvYMS4yWAPMzftjBqPhWgXQRnGCSEJrC1de8avm9ovgcyYEJ7/bB9fHZB01rURcXK+ysoj4yDdW7cS88UOvqis+lLHodbosbFYExKwpmcQOmECjr59sfftiy093RyjeAqBhga8pWX4SkvwlpTiKzmIFhFB+PTpWKKj2+PyuhdfsxmItQegpsgMspqWrbHS7KxzuAdqeAqEpxBZtRk2lR5T4zxg1loPfXG01mkNgbg+ZnOsu/boPVNfs1nzDUuGpMHQO9kMyJAYs+n4cEcgd415v9URbjb3RvUw99E9zBpvB2jY12TeLxWiEwVlGCe6EilrLMMf8KOfwV+5uqa4fXwWv/jfVlbnVTIq68KecKAtAk1NZq/g/Hw8+QXm0BwjgOFvacI1AvjLy2navAVvUctQfaWwZWfhS0kl4coZ5jjU9HRsGRlorlBzKInbjdHUZA4t8fmxxJudk7S29Fw9Cc3lwp7VA3tWkPQHCATMJtzGCjPsvO6jHYa8jWbAeRrMIRueRvNeaH2pudUdNGuex3NGmeHrjIKKPbBvsfn6FoMBNrV8YwszwzQyDbK/a97DTBwIMdlSsxTiLARtGPsNPxXuCuJD4s/otdcOTeXJj3fx/NJ9QRvGhmGOfTxVx6FAUxONa9fSsGw5DStW4K+uNmfmcZjDO5TTAQZ4CgrwHTz45RdbLOb90ZZJDtA09PBwHAMGEHXTjTgGDMDRLxc91MXixYsZcrJ7kCeZHOKCYBhmpyFPHegtPV8tNvNrbyMUr4eiNeZWvNasRbZGt7eMlwyF0Dizlpk+xhwuEpZg1lQjW3rQ2kNPLI+7xrxXW3uAjVu/YPD4r5ivs4d1zM9AiAtUUIbxsRN/nGkYO206N4/O4C+f7GZPWR0944PnQ6c5L4+auXOpfW8e3uJiLLGxx4xlTUQLddG0YSNN69ZheL0om42Q4cNwDByA0eQ+Wlt1uyEQIGTEcOyHewZnZpo127OY0eiC4veZnZYays1aavkus5m37Atz39TKcp5Kg/h+kHs1pAw3Q9Vib+m529Jr1+o4em9Ut57+fKd9L2Xew3VGQkIu1cVWiO159ucTQpxSUIbxsRN/DIwbeMavv2VMBv9YspcXlubx2LVn/vrzzTAMfAcPmtP92WzmZrejbHbAoH7RYmreew/35s2gabjGjCH8isvN2YAOltCct4+Gzz8n0NCAvXdvom6+GdfYsYQMH9Zlh690Oc31ULYdSreRkb8aPvjwmDGnLUNTGitaOhcdxxEJ8X2h35Xm/VZHpDlm1O81m539zebwl+Qh5ia1UiGCTlCH8dn0qAaICbVz3bBU3lxbxI8uzSE+rGsFkqeomKYNG1qG9GyneccX+KtP8iF/DHvfvsT/5CeEX3YZ1oSTtxYEPJ6zvicbFLxuKNtm3o/VtGOm2tPNQDx8H7a5ztzXl0HpFijZag69wZzDtwfAwfCWWmXL2NOItKMzFB3eXHEQ28vs5SudBYW4oAVlGIfbwnHojjMea3ys28dn8Z/V+/nX5wXcP613O5bu7PjKy6n94ENq582jaZPZi0ZZrdhzcgibOsXsUZyRAYGAOafu4SXDfF6cgwfjyMlp9T0uuCA2DCjbAXs/NbeC5WZnqDMR1cOchGHQjZDQHxJyWbJhN5dMmtIxZRZCBKWgDGOl1FmPNT6sR6yLS/sl8O+VBXx3QvZ5mSLTMAwMt/vo0mbVNTiWL2f/v1+lYcUKCASw9+lD/P0/xjV+PPasrC/N5ytaeBpbZk4qb5m8vtxsLnZXH52q0F1tjouta+mAFpsDw74NGWPN+68Bvznt4OH94Y5Q9tCj92OdUSed8MHQ8s7zBQshurugDGPgrGbhOt6dl5hTZM5ZU8h3xrX/kBhfVZU5uf2q1TSuXo0nP/+E1WUiAE9aGjEz7yDiq1/F3qtXu5ej2/C6W3r2FkNNsRmkh4fq1JWasyzVl504mcQRqmVy+pbm47RRkD3J3GScqRCiEwVvGLsSWHVw1TmdY2h6FCMzo3lxWR43j8nA2g5TZHqLi6l89TUaPv+c5p07AVAOByFDh+AaPw49MtJcxDvC3K/ft49xN914YU1A4muG0q3mUJ4DG82va4rM2u7x7OHmPdewREgdYX59eBrDkNij92mdUeakETIGVgjRBQVtGCe6EilvKscX8GHRzv4y75qQxXdeWcu8zQe4ekjqWZ/HU1hIxaxZVL/zP1CKkOHDiPvB9wkZNQpn//6nXIbN724K/iCuKzXv1xYsN8fQlm6HQMusXCExkDQIkgdDeCpEpByZEYrwJJkXWAgRFNqUUkqp6cBfMFf8esEwjMeOez4d+CcQ2XLMQ4ZhzG/nsp6RhJAE/Iaf8qbyI72rz8aEnHhyEkJ5bsk+rhqccspgNAIBMIwTpmT05OdT/twsaubORWkaUTfcQMwdt2NNSjrrMnVr3iYo3w1l28nZ+TZs+bE52xOA1QWpw2HsvUeH8USkSU9jIUTQazWMlVI68DdgKlAErFFKzTUM49h1Tn4BvGEYxrNKqX7AfCCzA8rbZseONT6XMNY0xcyLs7n/zU0s3nWIib2/PCzIU1hI9Zw5VL/9X/xVVebMU4eXcLNaCdTVoaxWor7xdWJuuw1rQtdZzLpDBQLmcJ8DG6Bk89HJLaoKODwEKF53QfZ4GPotyLjIrAHrQdtYI4QQp9SWT76RwB7DMPYBKKVmAzP48qJjBhDe8nUEcKA9C3k2znWs8bGuHJTMEx/t5Lkle5nYOx7D76d+yWdUvf46DcuWgaYRNmkS9j69MXw+8PkwvOYC53pkJFFfuwFLXNw5l6NLMgxzvdeqAqjKN4P3wAY4uMlc5g7MaR1jekHyUBh0E8T1hrg+LNt2gAkTJ3dq8YUQoitQhmGc/gClrgOmG4Zxe8v3NwOjDMO495hjkoCPgCjABUwxDGPdSc41E5gJkJCQMGz27NntdR3U19cTGnp0bt1GfyM/KfoJV0ddzaTwM1/L9Xgf5nmZvdPDn2IL6PPf19ArK/FHRNA0bhxN48YRiIo85/c4meOv63xTAS8Odxn25grszeUtWwUO9yEc7jIc7jL0QPOR4wPKQn1oD+rCeh7ZGkPSME7Scaqzr62jyHV1L3Jd3Ut3vq6JEyeuMwxj+Mmea682wZuAVwzDeEIpNQb4t1Kqv2EYgWMPMgxjFjALYPjw4caE9lqoHHPh82PPZxgGv5vzO1SsYsLYc3+f4WN81M/8PX3mzsHZI5O4X/2KsEkTO3yc7/HX1eFqiqBwtdmRqnC1WcMNHLfEYUgMhCdD/CCIzICoDHMfmY4Wk024xX6kmeR0zvu1nSdyXd2LXFf3EqzX1ZYwLgaOHYSZ2vLYsW4DpgMYhrFCKeUAYoHjVgc/f5RSDI4bzPrS9ed8LsMwaHpxFves+g8b43oy8ulZhGd18w5YhmGuSXtwExzcaO4PbDTXqAVzwYHkoTDmbnNhgvAUM4DDk81JMYQQQrSbtoTxGqCXUqoHZgjfCHz9uGP2A5OBV5RSfQEHcKg9C3o2hiYMZUnREiqaKohxnt1yiIbXy8GHH6bm7f9i/+rlPGK/mBkby/l9dwzjyjxz2sd9i2D/Kmg4/LeSMudIzrzIHKubOgISB5zbij9CCCHarNUwNgzDp5S6F1iAOWzpJcMwtimlfgOsNQxjLvBj4Hml1A8xO3PdarR2M/o8GBo/FIANZRuYknHmcwX76+sp/sF9NCxfTuzddxP7vXuZ8c5W3l5fxD0Ts0mN6uLLBTZVQd5SM3z3fmp2sAJzuFDPyebQoaRB5pzKx69lK4QQ4rxp0z3jljHD84977P+O+Xo7cFH7Fu3c5cbkYtftrC9bf0ZhbPj91L7/Pof+8le8JSUk/fZRIq+9FoB7JmYzd2MxP35jE/+5YzS61oXGwHqbYP9K2LcY8paYzc4Y5lzKPS6G0feYUz/GZMvYXSGE6EKCelCnVbcyIHZAm+8bG4ZB/eLFHHrqzzTv2oW9X18yHvs9ISNGHDkmNSqEh6/M5YG3NvP80n3cdUl2RxX/9AIBc7KMA+tbpo1cDwc3H137NnUETHgIelxiTqQhTc5CCNFlBXUYg3nf+MUtL9LobSTEeupm5cb16yn70xM0rV+PNSOdlKeeJGzaNJR24nzU1w1LZdHOMp74aCfjesbSPyWiIy/B1FAORWuhaLXZy/nARvDUmc9ZXWZz88g7IGsCpI+RZmchhOhGgj6Mh8UPY5Yxi42HNjI2eexJj6lfsoTCu76LJTaWxIcfJvLaa047ZEkpxW+vGsC6girum7ORed8bh8PazgsQBPyw5xP67Pg7bP5hy+L1mAvdJ/aHgTdAylCzx3Ncb1kAQQghurGgD+NB8YPQlMb60vUnDWNvaRkHHvop9pwcMl//D1pI2zplRbls/On6Qdz84mp+P38Hv57Rv30KXLkPNrwKG1+HugPEWMKg5yXmlJGpI8xOV7Yu3nFMCCHEGQn6MHZZXfSO6s36shPvGxt+PwcefJCA203KU0+2OYgPG98rjtvG9eDFZXlM6BN/wrzVbRbww465sPoFKFgGSoOeU+Erj/N5iZNLJk09u/MKIYToFs59gd5uYFjCMDYf2ozX/+WZpCqef57GVatI/MUvsGdlndW5H5jWm94JYTz41mYq6ptbf8Gx/F7Y8Br8bSS8eSvUFsOkX8IPt8E33oB+V2Jo0vFKCCGC3QURxkMThtLsb2ZbxbYjjzWu38Chp58h/KtfJeKaq8/63A6rzp9vHExNo5cfvbEJf6ANw6u9bljzAvx1KLx7tzmj1fX/hO+tg4vvN2e5EkIIccG4IMJ4SPwQwJz8A8BfU0Px/T/GmpxM4q8fPuUaxW3VNymcX8/IZcmuQ/xxwc6THxTwQ/4yeP9++HN/eP/HEJYIX38T7lwKuVdJJywhhLhABf09Y4BYZyyZ4ZmsL13Prbm3cvAXv8RXdojM1/+D3k6rf9w0Mp1tB2r4x5K99E0KY8bgFHMs8P7PYdv/zHvC9aXmnM+9psLImZA5XibfEEIIcWGEMZhN1QsLFlL1xhzqPv6Y+AcewDlgQLu+x/9dnsuuknp+/fZqRpTtJ/mLV8ze0RYH9LrUrP32miZjgIUQQnzJhRPG8UNZuuZtSl95HNfYsUR/+9Z2fw9bfRGvpM7FX/IKYZ834k0ahvWa56H3ZRLAQgghTumCCeMhsYP57vwAfgIkPfrISWfWOnE8Ja4AACAASURBVGuV++DT38K2dwgBqrMu44ZdI4ERvJY7Cqt+QdyaF0IIcZYumJQIfX85/QsMVlzXB2tyO/VWbqyEDx6CZ0bCzvkw5h64bzORt7zKN667ltV5lTw8dxtdYAErIYQQXdgFUTP2FBVR9sQTFPWLY06vcm43jHPrQe11w6p/wNInzfmhh9wME39m9o5uMWNwCtsP1vLckn1EOK08MK33OffaFkIIEZyCPoyNQICDP/s5StOo/uFNlO77OwcaDpASmnJ2J8xfDu/cBTX7zc5YU38N8X1PeuhPpvWhtsnH3xfvRdcUP5qaI4EshBDiBEEfxlWvv07j6tUkPfoIA3MHwL6/s750/dmF8dqXYf79EJUJt8yFrEtOe7imKX57VX8Mw+DpT/egKcUPp+ac3YUIIYQIWkEdxp7CQsr+9ASu8eOJuPZawowAYdYw1pet54rsK9p+Ir8XFvwMVs+CnlPgupfA0bZlEzVN8burB+ALGPzlk93omuL7k3ud5RUJIYQIRkEbxoZhcPAXv0TpOkmP/AalFLrSGRw/mHWl69p+osZKePNbkPcZjP0eTPn1Gc+UpWmKx68dSCBg8OTHu9A1xT0Te57hFQkhhAhWQdub2r15M42rVhH3/e9jTTzasWp00mjyavIorC1s/SRlO+D5SbB/JVz1LFz66FlPWalrij9eP4irBifzxwU7mbNm/1mdRwghRPAJ2jCumj0HLSSEiGuu+dLjUzKmAPDx/o9Pf4JNs80g9jbCrfNh8NfPuUy6pvjT9YO4qGcMD8/dTl55wzmfUwghRPcXlGHsr6mhdv58wq+4Aj3U9aXnkkOTyY3J5eP8U4SxpxHevRfeuROSh8DMJZA2ot3KZtE1/nT9IGwWjftmb8DrD7TbuYUQQnRPQRnGNe++i9HcTNTXbjjp81MzprK1YisH6g98+YlDu+CFybDhVRh/v9ljOjyp3cuXFOHk99cMYFNRDU9/srvdzy+EEKJ7CbowNgyDqjlv4Bg0EEe/fic9ZmrGVAAWFiw8+uDmN2HWBHNlpW++BZN/CXrH9W+7bEAS1w5N5ZlFe1hXUNlh7yOEEKLrC7owblq7Fs/evUR97cZTHpMenk7vqN4s3N8SxjvmwX9vh6RBcNcyc/jSefDwlf1IjnRy35yN1Lm95+U9hRBCdD1BF8ZVs+eghYcT/pXppz1uasZUNpRtoLRsK8z9nhnEt7wL4e00b3UbhDms/PlrgymuauLX720/b+8rhBCiawmqMPZVVFD70UdEXDUDzek87bGHm6o/+fAHZo/pa54Hi+18FPNLhmdGc8/Enry1roj3Nx887+8vhBCi8wVVGNe88w54vUR97WutHpsVmUW2LZqFjfvN8cNxvc9DCU/u+5N7MSg1gh++sZF3NxZ3WjmEEEJ0juAJ40CAqjlvEDJiBPbs7NaPP7SLqYcKWed0UNH/6o4v32lYdY2Xvz2SwWmR/GD2Rp78aCeBgCy7KIQQF4qgCWPbF1/gLSwk6qZTd9w6wueB/97BFK8iAHxatKjDy9eaaJeNV28bxfXDUvnrp3u49/X1NHn8nV0sIYQQ50HQhLHzs6Xo0dGETWlDT+glj8PBjeRMf5KM8IxTTwByntksGn+4biA/v6wvH2wt4YbnVlDllklBhBAi2AVFGHtLS7Fv3kzktdeibK10wtq/EpY9CYO/icqdwZT0KawuWU21u/r8FLYVSinuuDiLF24Zzr5D9fx6hZvPdh3q7GIJIYToQEERxnULFoBhEHnD9ac/0DDgo19CWDJ85TEApmZOxW/4WVTY+U3Vx5rcN4G37x6LwwK3vLSa+9/cRE2jjEUWQohgFBRhHHXzzVT+/GfY0tJOf2DB51C0GsbdB/YwAPpF9yMlNIWPC7pGU/Wx+iSG85uxTu6ekM07G4qZ8tQSPtxa0tnFEkII0c6CIoyVUvhSU1s/cNmTEBILg7/xpddOSZ/CioMrqPPUdWApz45NVzw4vQ/v3nMRcaF27np1HXe/to7y+ubOLpoQQoh2EhRh3CYHN8OehTD6u2AL+dJTUzOn4gv4+CDvg04qXOv6p0Tw7r0X8cC03izcXsY1f/+c4uqmzi6WEEKIdnDhhPHyP4MtDEbcfsJTA2MHMjBuILM2z6LZ33VrnFZd456JPZlz52iqGj187bkVFFY2dnaxhBBCnKMLI4wr9sK2d2DEd8AZecLTSim+N+R7lDaW8tautzqhgGdmSHoUr90+ijq3j689t4KCiobOLpIQQohzcGGE8edPg2aF0Xef8pBRiaMYkTiCF7a8QJOv6zf/DkyN5LXbR9Hk9fO151ay71B9ZxdJCCHEWQr+MK4rgY2vweCvQ1jiKQ9TSnHv4HspbypnzhdzzmMBz17/lAhenzkarz/AjbNWsqdMAlkIIbqj4A/jlX+HgA/Gfq/VQ4cmDOWi5It4ceuLNHi7R9Nvn8RwZs8cTcCAa/6+nN/N38FeqSULIUS3Etxh3FQNa16CfldBTBsWjwDuHXIv1c3VvLbjtQ4uXPvplRDGm3eNYUx2DC8ty2PyE0u44bkVvLOhCLdX5rcWQoiuLrjDeM0L4KmDcT9s80v6x/ZnQtoEXtn6CjXNNR1YuPbVI9bFczcP5/OfTuLB6b0prXXzwzmbGPW7T3hzbWFnF08IIcRpBG8YGwasngU9p0DSwDN66b2D76XOW8e/tv+rgwrXceLDHNw9oSeLfjyB/9wxij6JYTzw1mb+snA3hiHLMgohRFcUvGHsqYf6Uuhx8Rm/tHd0b6ZlTuPV7a9S5a7qgMJ1PE1TjM2O5d+3jeKaoSk8tXAXP3tnCz6/rAIlhBBdTfCGcX2ZuQ9NOKuX3z3obtx+N7M2z2rHQp1/NovGE9cP4p6J2by+upCZ/15Ho8fX2cUSQghxjDaFsVJqulJqp1Jqj1LqoVMcc4NSartSaptS6j/tW8yzcDiMXXFn9fKsyCyu63Udr+54lTd3vdmOBTv/lFI8MK0Pj17Vn8U7y7hp1kqZ21oIIbqQVsNYKaUDfwO+AvQDblJK9TvumF7AT4GLDMPIBe7rgLKemfpSc3+WNWOAh0Y9xPiU8Tyy4hEW5C9op4J1nm+OzuC5m4ezs7SOy/+6jHc3Fst9ZCGE6ALaUjMeCewxDGOfYRgeYDYw47hj7gD+ZhhGFYBhGGXtW8yz0HDI3J9DGFs1K09MeIIh8UN4aOlDfF78eTsVrvNM7ZfAG3eOISbUxg9mb+T6f6xgS1H36TUuhBDBqC1hnAIcOzamqOWxY+UAOUqp5UqplUqp6e1VwLNWXwpKg5DoczqN0+Lk6clPkx2RzX2L72PToU3tVMDOMzA1krn3juPxaweQX9HAlX9bxk/e2syhOmm6FkKIzqBaa6ZUSl0HTDcM4/aW728GRhmGce8xx8wDvMANQCrwGTDAMIzq4841E5gJkJCQMGz27NntdiH19fWEhoYe+T5n5zPEVKxlxdhX2uX8tf5anip5isZAIz9I+AHJtuR2OW9rjr+u9tboNZi718PHBT6sGkzLtHJpphWXVXXYex7W0dfWWeS6uhe5ru6lO1/XxIkT1xmGMfykTxqGcdoNGAMsOOb7nwI/Pe6YfwDfPub7T4ARpzvvsGHDjPa0aNGiLz/w2tcM49mL2vU9CmsLjUlzJhkT50w0yhrK2vXcp3LCdXWQPWV1xsx/rTEyfjLP6P+rD42nPt5pVDd6OvQ9z9e1nW9yXd2LXFf30p2vC1hrnCIT29JMvQbopZTqoZSyATcCc4875n/ABAClVCxms/W+M/iDof3Vl4Irvl1PmRqWyrNTn6XWU8ujKx8Nqs5P2XGhPHfzcN7//jjGZMXw54W7Gf/4p/xl4W5q3d7OLp4QQgS1VsPYMAwfcC+wANgBvGEYxjal1G+UUle2HLYAqFBKbQcWAQ8YhlHRUYVuk/qyc+q8dSo5UTncM/gePi38lA/zP2z383e23OQIZt0ynHnfG8forBieWriLcY99yjOf7qa+WcYnCyFER7C05SDDMOYD84977P+O+doAftSydT7DgIYyCG3fmvFht/S7hY8LPuZ3q37HyMSRxDhjOuR9OlP/FDOUtxbX8OeFu/jTR7t4cVkeMy/O5ltjMwixtemfjhBCiDYIzhm43NXg93RIzRhA13QeuegRGrwN/G7V7zrkPbqK/ikRvPCtEbx7z0UMSovk8Q+/YPzji3j+s300eWRFKCGEaA/BGcZHpsLsmJoxQHZkNt8d9F0+KviIj/I/6rD36SoGpUXyyrdH8vZ3x9A3KZzfzt/B+D8s4sVlebJMoxBCnKMgDePDs291XBgD3Nr/VvpG9+W3q37bbReUOFPDMqJ59fZRzJk5ml7xoTwybzsX/2ERLy+XUBZCiLMVpGF8botEtJVVs/LIRY9Q66nl96t/36Hv1dWMyorh9ZmjmT1zND1iXfz6ve1c8sdF/GPJXqoaPJ1dPCGE6FaCO4zPcpGIM9E7ujczB87kg7wPeHvX20E13KktRmfFMOfOMfznjlFkxYby2AdfMOr3n/DjNzaxsbC69RMIIYRoW2/qbqe+FDQrOKPOy9vdPuB2Vh5YycMrHubj/R/z81E/Jy0s7by8d1cxNjuWsdmx7Cyp498r83lnfTFvry9iYGoE3xiVzvT+SUQ4rZ1dTCGE6JKCs2bccMhsolYdP6UjmM3VL057kZ+M+AkbyzZy9btXM2vzLDz+C6+5tndiGI9eNYCVP5vMb2bk0ujx85O3tzDi0YXc8a+1vLfpgPTCFkKI4wRvzTi045uoj2XRLHyz3zeZmjGVx9c8ztMbnmbevnn8cvQvGZE44ryWpSsIc1i5ZUwmN4/OYFNRDXM3HmDe5gN8vL2UEJvOpf0SGOYKdHYxhRCiSwjOmnF9aYd33jqVBFcCT054kr9N/hsev4fbFtzGMxuewR+4MGuDSikGp0Xyf1f0Y8VPJ/OfO0YxY3Ayn3xRxv8tb+KhtzdTVuvu7GIKIUSnCtIw7rjZt9rq4tSLeWfGO8zoOYPnNj/HnQvvpLypvFPL1Nl0TTE2O5bfXzOQpQ9O5NIMC2+vL2LCnxbzl4W7afTIdJtCiAtT8IVxwA8N5Z1WMz6W0+LkkYse4Tdjf8PGso3c8N4NrCtd19nF6hIiQ2zc1NfOxz+8hEty4nhq4S4m/mkxb64tJBC4sHqkCyFE8IVxYyUY/nZfselcXN3ral677DVCrCHctuA2Xtr6EgFD7pcCZMa6ePabw3jzrjEkRjh54K3NXPm3Zazc17nrjAghxPkUfGF8nmbfOlO9o3sz+6uzmZQ+iafWPcW3PvgWOyp2dHaxuowRmdG8892x/OXGwVTWe7hx1kru/PdaCioaOrtoQgjR4YIvjBvOz+xbZyPUFsoTlzzBb8b+hv11+/navK/xyIpHqHbL5BgAmqaYMTiFT348gR9PzWHp7nKmPLmER+Ztp7i6qbOLJ4QQHSb4wvg8LBJxLpRSXN3rat67+j2+3vfrvL37bS7/3+W8sfONC7bH9fGcNp3vTe7FovsncPWQFF5anse4xz/lO6+sYeH2Unx+aeIXQgSXIAzjrtlMfbxwWzgPjXyIN654g16RvXhk5SPc+P6NrDq4qrOL1mUkhDv4w3WD+OyBidwzoSdbimu4/V9rGf+HRTz18S62HajBK8EshAgCwTfpR30ZWEPAFtrZJWmTnKgcXpr2EgvyF/DUuqe4/aPbuST1En40/EdkRWR1dvG6hLToEO6f1psfTOnFJztKeW3Vfv7yyW7+8slubBaNvknhDEyJYEBKBMMzo8iK6x6/eyGEOCw4w9gVd96mwmwPSimm95jOxPSJvLr9VV7Y8gLXvHsN1+VcxyD/oM4uXpdh1TWm909iev8kiqubWFdQxdbiGjYXVfPOhmL+vbIAgDFZMXxrbAZT+iZg0YOv8UcIEXyCMIw7b/atc2XX7dw24Dau7nU1z258ljd3vcm7vEvDFw3c0PsGNCXBclhKpJOUSCdXDkoGIBAwyKto4KNtpby6soC7Xl1PcoSDb4zO4MYRacSE2ju5xEIIcWrB9+neBWbfOlfRjmh+Pvrn/HfGf8m0Z/LbVb/lWx98i73Vezu7aF2Wpimy40L57oRsPntwIrNuHkaPOBd/XLCTMb//lFtfXs0/P89nf0VjZxdVCCFOEHw144YyyBjb2aVoF1kRWdwdfzd16XX8Yc0fuO6967hjwB3cPuB2bLqts4vXZema4tLcRC7NTWRPWR2vry7k0y/K+NXcbfyKbWTFuZiQE8+MwckMSovs7OIKIUSQ1Yz9Xmis6PY142Mppbgy+0renfEul2ZcyrObnuX6967n8+LPMQyZNrI1PePD+OXl/Vh0/wQW3T+BX13Rj9SoEF5dVcCMvy3ngTc3UV7f3NnFFEJc4IIrjBsOmfsgCuPDYpwxPH7x4/x98t9p8jVx58I7uWHeDby/7318AVlgoS16xLr49kU9+Nd3RrL+l1O565Js3tlQzKQ/LebfK/Lxy5zYQohOElzN1PVdd/at9jI+dTzzrp7HvH3zeGXbKzy09CH+uv6v3NzvZq7pdQ0h1pDOLmK3EGq38NBX+nDdsBR+NXcbv3x3G7PXFPLzr/YlxmWnzu2lrtlHndtHvdtHUoSDYZlRhDusnV10IUQQCs4w7kKLRHQEm27jml7XcFXPq/is6DNe3voyj695nOc2P8cdA+7gxj43yj3lNuoZH8art43i/S0HeXTeDr7+/KknXVEK+iSGMzIzipE9YhiVFU2s9NIWQrSDIAvj7jH7VnvRlMaEtAlMSJvAxrKNPLvpWf649o/854v/cO+Qe7msx2UyHKoNlFJcPjCZib3jWbijFIumEeqwEOawEGa34LJbyK9oYHVeJWvyK3ljbRH/XFGAzaJx/6U53DYuC13rPuPahRBdT3CFcUPXnpe6Iw2OH8xzU5/j8wOf8+d1f+anS3/Kv7b9i/uG3cfY5ODoXd7RXHYLMwannPS55EgnY7NjAfD6A2wtruHvi/fyu/lf8NG2Uv50/SAyY13ns7hCiCASXNWm+jKwh4PV2dkl6TRjk8cy+/LZ/H7876n11HLnx3fyrQ++xfLi5dL7up1YdY0h6VHMunkYT94wiJ2ldXzlL0v514p8AtIJTAhxFoKrZlxfekHWio+nKY3Lsy7n0oxLeXPXm7y89WXuWngXuTG53DHgDiamT5Tm63aglOKaoamMyY7hJ29v4f/e3caHW0vIcXhp2nKQyBAbUS4rkU4bTpuOP2Ac2XyBAFZdIyHc0dmXIYToAoIsjMuCuif1mbLpNr7R9xtcn3M97+19jxe3vsh9i++jZ2RPvt3/20zLnIZdlw5I5yopwsk/vz2C11cX8rv5O/i82ccr29a36bUX58TxwKW9GZAa0cGlFEJ0ZcEXxon9O7sUXY5Nt3FtzrXM6DmDj/I/4vktz/PzZT/nD2v+wJXZV3J9zvX0iOjR2cXs1pRSfH1UOtcOS2Hex0voO2g41Y0eqpu8VDV6aPL4sWgKXdfMvVKU1Lp5aXkeVzyzjOm5ifzo0hxyEsI6+1KEEJ0g+MI4yIc1nQuLZuGyrMv4So+vsLpkNW/uepPXd7zOv7f/mxGJI7g+53ompk3EYZGm07Nlt+jEODX6JYe36fhvX5TJi8vyeGFpHgu2l3DV4BTuvCSL3glhqG608pgQ4twETRhrfg8018g94zZQSjEqaRSjkkZR3lTO//b8j7d2vcWDnz1IqDWUyemTuSzrMkYmjsSiBc0/kS4pzGHlvik5fGtMJv9Yspd/rsjnnQ3FZMW6mNY/ka/0T2RASoQEsxBBLmg+aa3eavMLuWd8RmKdsdw+4Ha+0/87rDq4ivl581lYsJB3975LjCOG6T2mMzl9MoPiBslEIh0oymXjp5f15Y6Ls/hgawkLtpYw67N9PLt4LymRTi7NTWBMVgwjMqOJcsnvQYhgEzRhbPNUmV9IzfisaEpjTPIYxiSP4Rejf8HSoqXMz5vPmzvf5LUdr+G0OBmaMJTRiaMZnTyanKgc6ZHdAWJD7dw8OoObR2dQ1eDh4x2lfLi1hNdW7efl5fkA9EkMY2SPaEb2iGZcz1giQySchejugiiMD9eMJYzPlV23MyVjClMyplDvqWdNyRpWHlzJyoMreWLdE7AOIu2RDI4bzOD4wQyJH0JubK70zG5nUS4bNwxP44bhabi9fjYX1bA6r4JVeZW8ta6If60oQNcUo3pEMy03kan9EkiOvHDH2AvRnQVhGEszdXsKtYUyMX0iE9MnAlDWWMaqg6tYU7KGDWUbWFy0GACrZqVfTD96R/UmMyKTzHBzSw5NRtf0TryC4OCw6kdqw/dizgK2pbiGhdtL+Wh7qblW89xtDEyNYFhGFJbjpufUNY2e8aEMSo0gOy4UTabvFKJLCaIwbmmmdsV1bkGCXHxIPFdkX8EV2VcAUOmuZGPZRnM7tJEP8z+k1lN75HirZmVw/GB+MfoXZEVkdVaxg45V1xiaHsXQ9CgenN6HvYfq+WhbKQu2lTBnTeEJx3v9Abx+c3Ywl02nf0oEg9IiGZYRxZjsGFmNSohOFkRhXA3OaNDlQ+V8inZEMyl9EpPSJwFgGAZVzVUU1BaQX5NPXk0e7+x5hxveu4EfDvshN/W5Se41d4DsuFC+OyGU707IPunz/oDBvkP1bCysZnNRDZuLqnlleT6zPtuHrikGpUYwrmcs43rFMSQ9EqsuvyMhzqcgCuMqaaLuApRSRDuiiXZEMyR+CAA397uZh1c8zGOrH2NR4SIevehREl2JnVzSC4uuKXolhNErIYzrh6cB0Ozzs3F/Ncv2lLN0dznPLNrDXz/dg82iER9mJy7MTlyondiWfU2JF+OLMhIjHCRFOIhwWmXIlRDtJIjCuBpiJIy7oriQOJ6Z9Axv736bP6z5A9e8ew0/HfVTXIasctSZ7BadUVkxjMqK4ceX9qamycuKvRVs2F9FWV0zh+qa2V/ZyLqCKioaPAC8sm3NMa/XSI8OYUBKBP1TIhiYGkG/5HBCbEHzsSLEeRM0/2tsnmoIHdDZxRCnoJTiupzrGJU0ip8v+zk/W/YzIvQIPvv8My5OvZjRSaMJsYZ0djEvaBFOK9P7JzK9/4mtFl5/gLkfLSaz3xBKatyU1LopqWkir7yB5XvL+e+GYgA0BTkJYYzvFculuYkMTY+StZ6FaIMgCmNppu4O0sLSeHnay3yY/yFz1s1hQf4C3t79NjbNxoikEYxKHEXv6N70ie5DtCO6s4srWlh1jRinxrCMqJM+X1rrZktRDZuLa9iwv4p/fl7A80vziHHZmNQnnktzExmUFoHTqmO36Fh1JU3cQhwjOMK4uR490CxjjLsJXdP5atZXce13cdH4i1hftp4lRUv4rOgzlhcvP3JcvDOenOgcekX1ItmVTKIrkYSQBBJdiUTaI+XDvAtJCHeQ0M/BlH7mH8R1bi9Ldh3io22lfLithDfXFX3peE2Zw7UcVh2HRcNh03FYdJw2HadVJzclnCsGJpObHC6/Z3FBCI4wri8197JIRLdj1a1H5sl+cMSDVLmr2Fm1k52VLVvVTlYeXIkv4PvS6+y6nYFxA5mcPpnJ6ZOlQ1gXE+awcvnAZC4fmIzHF2BVXgX55Q24vQGafX7c3gBurx93y9dNXj/NXj9NXj91zT5eXJrHc0v2kRXr4vJByVw5KIme8bKilQhebQpjpdR04C+ADrxgGMZjpzjuWuAtYIRhGGvbrZStqS8z91Iz7vaiHFGMThrN6KTRRx7zB/xUuispaSihtLGUkoYSiuuLWXlwJY+tfozHVj9Gbkwuk9MnMzxxOAC+gA+/4T8S4gPjBhJua9tKSqJ92Swa43vFMb5X2+cAqGrw8OG2Et7bdICnP93NXz/ZTVasi96JYWTHhZId7yIrNpTMGBfVTR7yKxopqGggv9zc2ywa03ITmdw3njAZQy26gVbDWCmlA38DpgJFwBql1FzDMLYfd1wY8ANgVUcU9LQaDoex3DMORrqmExcSR1xIHAP4cie9/Jp8Ptn/CZ/u/5S/bvjrKc9h1+1MzZjKNb2uYXjCcGn67OKiXDZuGpnOTSPTKat1M3/LQZbtKWdnSR0fbS/FHzBO+roQm05GjIvKhmY+2FqCTde4OCeWr/RPYkq/BCKcEsyia2pLzXgksMcwjH0ASqnZwAxg+3HHPQI8DjzQriVsC28TPt2JRWrGF5zMiExuG3Abtw24jdKGUnZV7ULXdCzKgq7p6Eqn2d/MR/kfMT9vPvP2zSMtLI2rel7FtMxppIelSzB3cfHhDm69qAe3XtQDAI8vwP7KBvYeaqCgooHIEBuZMS4yY0KIC7OjlCIQMNhQWMX8LSV8sOUgC3eUoWuKrFgXfZPC6ZMURt+kcPomhmMYJw92Ic6ntoRxCnDs/HpFwKhjD1BKDQXSDMN4Xyl1/sN40I0sq0pkgoTxBS3BlUCC6+StI6OSRnH/iPtZWLCQd/a8w9MbnubpDU8TZgsjNybX3GJz6R/Tn6TQpPNccnEmbBaNnvFhp72HrGmKYRnRDMuI5hdf7cumoho+3VHK9oO1rCuoYu6mA0eOVUDo4gW47BZcdh2X3UKMy8awjChGZcUwMDUCu0XmVxcdS7X2V6FS6jpgumEYt7d8fzMwyjCMe1u+14BPgVsNw8hXSi0G7j/ZPWOl1ExgJkBCQsKw2bNnt9uF1NfXExoa2m7n6yqC9bqgc6+t3FvOTvdOCj2F7Pfsp9hTTIAAAAmWBHJDcsl15pJtz0ZXJ34Qew0vASOAXTtxpapg/Z0F03U1eA2K6gIU1gU4VN9MQLPi9oHbb+D2QaU7QHG9+dlo1aBnpEZOlE6oTREw/r+9O4+PqrwXP/55ZslM1slkYQJJgIQQtoQQQQQXiFAEvUqsBam1XqQ/6EvbalvbKlp7y23RWrEu7fWlolcUr1YQSqVKRSlQpOISEAkECGELYQkhyyQhVBUA/gAAIABJREFUJJOZeX5/TJgmIYEAgcmM37evec2cc55z5vlmBr9zznkWWh4ar4Yos2JYgpFeET1rCNFQ+rxaC+a4rr/++s1a61EdbetKMh4LzNNaT25ZfhhAa/27lmUbsBeob9klCagCpp6tEdeoUaN0QUH3tfFav349eXl53Xa8niJU44KeFVuTp4k91Xv48viXfFz2MQXlBTR7m4kyRzG2z1hsFhvlJ8s53nCc8oZyappqMBvM3DbwNmZnz27TmrsnxdWdvm5xVZ108fn+Kj7bX8ln+6rYeayWs/3vsn98BOMzExmXmciY9HgiLYHtrPJ1+7yCgVKq02TclW/LF8BApVQacBj4NvCd0xu11k4godWbraeTM2MheiqL0UJWQhZZCVncNfQuGpob2HR0Ex+XfczGwxtp9jb7+zjnJObgiHRwpP4Iy4uX85c9f2Fa5jRmZ8+mV4TcKgkVcZFhbUYkO9nkpsntxagUBoNvvG+DUhypOcWG4gr+WVzB0oIyXt90ELNRMSAxikxHNJkO3/OgpGhS7REyfaXo0DmTsdbarZT6EbAaX9emV7XWO5RSvwEKtNYrL3UlhbjcIswR/j7MZzNn+Bxe3vYy7+x+h+XFy5mWOQ3zSTPug24sRgtWkxWL0UK4KZyYsBiiw6IJN4VLo7Eg5LunfOb69MQo0hOjuPuaNJrcHgoOVPOvkhPsOlbHltK296dt4WauSotj7IB4xqTHM8gRLclZAF3sZ6y1XgWsarfuvzopm3fx1RIiOCRHJTPv6nnMzp7Nwm0LWbJ7CR7t4fX1r3e6j8lgIiYsBpvFRr+YfgywDWBArO+RZkvDYrRQ31yPs8lJbVMtziYnbu0m3ZZOclSyJPIezGIyck1GAtdk+C8WUt/kZk95HbtbkvOmfZV8WOQbqMgeYWZEaiwRYSaMBoXJoHzPRkVilIXUuAj6xkXQNz4CR7RVEncIC40RuIQIsJToFH5zzW/42aifsXrDanJG5tDoacTlcdHobqTB3UCtq5Y6Vx21Tb7nqsYqDtQeYOPhjf7BSRS+MZu92tvh+0SZo8i0Z5Jpz2RQ3CBye+WSbks/a4Ju9jZz0HmQuPA47Ba7JPPLLMpiIrevndy+dr49ui8AZdUNfLqvik/3VbLjSC3NnlN4vBq314vbo2n2eKk66aJ1d+owo4G+8REMckT7L3sPSoqmb1wERoPC5faNZHbK5aHB5abeJV22gokkYyG6kc1io5e5F4PiBnV5n2ZvM4dqD7HXuZeSmhLcXje2MBs2i81/Bq2UYk/1HoqriymuLuZv+/7G27t9vRF6hfdiTJ8x/pHLYiwxFFYUsrl8MwXlBXxV8RWn3KcAiA6Lpn9Mf/rF9KNfTD+So5JJikzyPSKSMBt9g2J4tZeKhgpK60oprS2lrL6MxvpGrmy+kkizTH15sVLsEUwbGcG0kSmdlnG5vRypOUVpVQOlVQ0cqmpgb8VJth9xsmr7UX9jMrNRoTW42w2EooCX9/yL8QMTuC4zkRGpsZiNvhbfWmuqTro4VH2KsuoGkmPDyUmJlTPvAJJkLESAmQ1m0mPTSY9NZ1K/SZ2Wy+2V63/t1V7K6sr44tgXbDq6iQ1lG1i519d8w2Qw+c+0M+2Z3JpxK9kJ2TibnByoPcDB2oNsLt/Me/veO+M9EsITiA6L5mj9URo9jf71CoVG886Sd8hLzeM/0v6Da5Ov9Sdv0f3CTAb6J0TSP+HMHz8NLjd7yuvZXV7HvoqTGJRv9DGr2UhEmInwMAP/3FxEqQv+Z10Jf1xbQrTFRHaKzZeEqxo46fK0OWZCVBh5g3oxcXAvrh2Y0OVhRJs9XrT21VdcOEnGQgQhgzLQN6YvfWP68q3Mb+HVXnZV7WLTkU04XU5yE3O5wnEFNout02Occp/i6MmjvjG/T/rG/D7WcAxnk5Nrk6+lb7Tv+P1i+uGIcLD4w8UciT3C6gOrWX1gNTaLjcn9JpOfkU92QnaXL3+7vW5qmmqoPFWJy+NiSPwQTAb5X9H5iAgzkZMaS05qbKdl7M4S8vKuwdnQzCd7T7BhTwXbD9eSYg9nTHo8qXERpNrDSbaHU3K8nn/sPM5HReUs21yG2agYnhJLij2cpBgrSTYrvW1WEqIsHHU2sud4PSXH69hTXs/+E76xwPMGJTJ5WBITBst44BdC/gUIEQIMysDQ+KEMjR/a5X3CTeGk29JJt6V3qXy6NZ3vjfkeD41+iE1HNvHevvdYuXclS4uXkmZLI39APrcMuMXfvaveVc/2yu1sq9jGtoptlNaVUtVYhbPJ2ea4ieGJ3Jx+M1MHTCXDntH1oDvg1V5Ka0sxGoykRqde1LFChS3CzI3Zvbkxu/OR5Yb1sZE/Ihm3x8uW0hr+saucLw/W8GVpDcecjbg8bdswGBT0i48ko1cUk4Y6qDnVzEdF5awq9I0HfnVGPN8Y4iAtIRJHjIVeMVaiLSZpr3AWkoyFEOfFbDAzLmUc41LGUe+q58ODH/Juybs8u+VZ/vjlHxnlGEVVYxV7a/ai8d3HTLelkxGbQZw1jnhrPHHWOOxWOx7tYdX+VbxR9AaLdixiWPww8jPycUQ4KG8op/xkue+5oZyTzSdxRDjoE9WH3pG96RPVh8TwRMrqyyiqLKKosohdVbs42XwSgOEJw5k6YCpT0qac9QpBax6vB6fLSbOnmV4Rvb52ycNkNDA6LY7RaXH+dVprqhuaOeo8RUVdE44YK2kJkVjNbUemm5+fxZeHqvlg+zE+2HGM9bsr2mwPNxvpFWMhIcqCPSKMuEgz9ogw7JFhRFpMNDV7aHD5Ho3NHprcHob1sXHDMAe9oq2XJf5AkmQshLhgUWFR3DbwNm4beBsHaw/ybsm7rDu0jqTIJG7ofwM5CTlkJWaddfrKG9NupPJUJav2r+KvJX/l8c8e928zGUw4Ihw4IhzYLXYO1R3is6Of0eBuaHMMi9HCIPsgbk6/mWHxw3A2OVm5byXzP5vP77/4PeNTxnND/xtQKKoaq6huqqa6sZqqxir2H9vPs399luqmamqaavwt2WMtsQyLH8bQ+KEMS/CNX+6IcHztErRSirjIMOIiw85arvV44I/cNISDlQ0cdTZyvK6R47VNlNc2Ul7XRNXJJg7XnGLHESeVJ1243G3Pus1GRbjZiNGg+PPnh/jVu9sZ2dfOlKwkJg8797zlHq+musFF9UmXL/Gfo949hSRjIUS36BfTj/uvuJ/7r7j/vPeND4/nrqF3cdfQuyipLqHJ04Qj0kGcNQ6DatswSGtNrauWoyePUn6ynKTIJAbEDjjjvvPMYTPZXb2bd0veZdX+VawpXePfplDYLDZiLbEYMJBuS+cK6xXYrXbirHEoFLurd7PjxA5e3f4qHu1r7BRriSUjNoOB9oFkxGaQac9koH2gtDBvRynVaeOz1rTWnGr2UN/kxmo2Em42tmnxXVxezwfbj7F6xzHmv7+T+e/vxG5R2L5Yh9loIMxkwGw0YDQoahpcVJ10UXOq2d/S3KBgVP84bhjqYPKwJFLjIi516BdMkrEQokc5131jpXyJ1GaxMThu8FnLDY4bzODRg3lg1APsrtpNuCmcWEssNovNn7zPNdZxo7vRn5j31OxhT/UeVu5d6b8crlCk29LJSsgiOyGb7MRsBtoHYjZII6ZzUUoREWYiIuzMVKSU8vel/vE3BlJa2cDqHcf451d7iE+MxeX20uzx4vJo3B4vmY5o4iLDiG85i7dHhrH3eD0fFpX7E/ngpGiuG5hAeJgJBSjl+/wMCoxGhdlgwGRUmIwGwowKq9lI/ojky/K3kGQshAh5ZoOZrISsC9rXarKSk5hDTmKOf53WmiMnj1BSXUJRVRHbT2zn48Mf8+7edwHf5fXT98ZjLbHYrXbsVjsJ4Qn+Pt1JkUk4IhyYjWZqXbUcrjvM4Xrf40j9EQzKQKwl1vfjwWrDFmYjyhyFPv1fy+mfUooBtgFEhQXnTEZd1Tc+gjnj0hnoLSUvL/fcO7R44IZBHKw8yUdF5Xy4o5xX/3UAj7drA6LYws2SjIUQoqdSSpEclUxyVDLjU8cD/07QhScK2Vm5k8pTlf5704fqDlHdVO0/m/YfB0W4KfyMe+CR5ki01mes74xBGRgYO5ARvUaQ2yuX3F65nGtGvo44m5zsrdnLXudenE1O0mLSGBA7gNToVIyGSzOns9Yat9d9Sfus94uPZPZ16cy+7t89B7TWaA0a33SYHq9v5DO3R9Ps9dLs0Xi7mLS7gyRjIYToBq0T9JT+Uzos09DcwLGGY236dte6anFEOEiOTvbvf7r1t8vjwtnkxNnkpKapxp+cTw+bqlA0e5vZWbmTL49/yd/2/o0lu5cAYMJE+J/DsRqthBnDsBqtWEwWLEYLYcYwLMZ/v65oqGBvzV4qGys7rHeYIYw0Wxrpsen0je5LclQyKdEpJEcl44hwnHei9mov2yq2sfbQWtaVruNg7UEGxA4gOyGbrIQshicOJyM245L2P1dKcbotnhGF2cgZLcQvJ0nGQghxmUSYI86rb3eYMYzEiEQSIxLPWi4vNQ/wdc3aU+Obl/vznZ/Tq08vmjxN/kej2zdeepO7idqmWv/6+PB4xqWMY0DsANJt6QyIHYDNYmO/cz8lNSXsrfEN1frV8a9YfWB1m7HTTcpEYkSiv7tanNU3BnqsNRazwYzJYMKkTBgNRgzKQOGJQtYfWs+JUycwKROje49mYt+JFFcXs+7QOlaUrAB8/eDzUvKYPmg6oxyjzqsVu7PJScGxAtzaTaY9k77RfTv8weD2uimtK2W/cz8xYTFk2jO73A2uu0kyFkKIEGE0GH2N1uIG0/tYb/Kuyruo452e47u1Zk8zx04eo6y+jMP1hymrK+N4w3Gqmqr8/curGqto8jR1eMwIUwTXpVzHhNQJXJtybZtub1pryurKKDxRyJbjW1i1fxV/P/B3+sf0Z3rmdPIz8js8ptvrpvBEIZ8c+YRPjnzC9hPb2/xgsBqtvtbvcZk4IhwcrD1ISU0J+537afY2tzlWr/Be/tbyA+0DuWXALWe06L8UJBkLIYToMrPRTGpMKqkxnY9wprWm0dOI2+vG4/Xg1r5nj/aQEJ5AmLHjvr9KKf+xb0q/iZ+P+jmrD6zmneJ3WFCwgOe2PEeqOZWX33+ZU55TNLobaXQ3Uueqo9HTiEEZyErI4vvDv8/Y3mOxmqz+yVWKq4pZW7qWmqYaekf2JiM2g2v6XEOGPYN0Wzo1TTXsqfa1lt9Ts4fPd31OdFh0pz8AupskYyGEEN1KKV/DtItlNVnJz8gnPyOf3VW7eaf4HQoOFBAdFk2iKRGryYrVaCXSHMmIXiMYnTT6jMvMrYeI1Vrj8rqwGC0dvt+1ydf6X7u9bioaKjosdylIMhZCCNHjDYobxKNjHmV949n7hZ+NUqrTRNyeyWCid1Tn43l3N5nzSgghhAgwScZCCCFEgEkyFkIIIQJMkrEQQggRYJKMhRBCiACTZCyEEEIEmCRjIYQQIsAkGQshhBABJslYCCGECDBJxkIIIUSASTIWQgghAkySsRBCCBFgkoyFEEKIAJNkLIQQQgSYJGMhhBAiwCQZCyGEEAEmyVgIIYQIMFOgK9Bac3MzZWVlNDY2nve+NpuNnTt3XoJaBVYg47JaraSkpGA2mwPy/kII8XXRo5JxWVkZ0dHR9O/fH6XUee1bV1dHdHT0JapZ4AQqLq01lZWVlJWVkZaWdtnfXwghvk561GXqxsZG4uPjzzsRi+6nlCI+Pv6CrlIIIYQ4Pz0qGQOSiHsQ+SyEEOLy6HHJONCioqICXQUhhBBfM5KMhRBCiACTZNwJrTW/+MUvyMrKIjs7myVLlgBw9OhRxo0bx4gRI8jKyuLjjz/G4/Fw9913+8s+88wzAa69EEKIYNKjWlO39t9/20HRkdoul/d4PBiNxrOWGdonhl/fMqxLx/vLX/7C1q1b+eqrrzhx4gRXXnkl48aN46233mLy5Mn88pe/xOPx0NDQwNatWzl8+DDbt28HoKampsv1FkIIIeTMuBMbN27kjjvuwGg04nA4GD9+PF988QVXXnklixYtYt68eRQWFhIdHU16ejr79u3jvvvu44MPPiAmJibQ1RdCCBFEeuyZcVfPYE+7XP1xx40bx4YNG3j//fe5++67eeCBB/jP//xPvvrqK1avXs2LL77I0qVLefXVVy95XYQQQoQGOTPuxHXXXceSJUvweDxUVFSwYcMGRo8ezcGDB3E4HMyZM4fZs2ezZcsWTpw4gdfr5Vvf+hbz589ny5Ytga6+EEKIINJjz4wD7Zvf/CabNm0iJycHpRRPPvkkSUlJvP766yxYsACz2UxUVBSLFy/m8OHDzJo1C6/XC8Dvfve7ANdeCCFEMOlSMlZKTQGeA4zAK1rrJ9ptfwCYDbiBCuB7WuuD3VzXy6K+vh7wDXixYMECFixY0Gb7zJkzmTlz5hn7ydmwEEKIC3XOy9RKKSPwPHAjMBS4Qyk1tF2xL4FRWuvhwDLgye6uqBBCCBGqunLPeDRQorXep7V2AW8D+a0LaK3Xaa0bWhY/BVK6t5pCCCFE6FJa67MXUGoaMEVrPbtl+S7gKq31jzop/z/AMa31/A62fR/4PoDD4Rj59ttvt9lus9nIyMi4kDi61M84GAU6rpKSEpxO5yU5dn19fUgOPypxBReJK7gEc1zXX3/9Zq31qI62dWsDLqXUd4FRwPiOtmutFwILAUaNGqXz8vLabN+5c+cFd0+SKRQvDavVSm5u7iU59vr162n/HQgFEldwkbiCS6jG1ZVkfBhIbbWc0rKuDaXUN4BfAuO11k3dUz0hhBAi9HXlnvEXwEClVJpSKgz4NrCydQGlVC7wEjBVa328+6sphBBChK5zJmOttRv4EbAa2Aks1VrvUEr9Rik1taXYAiAKeEcptVUptbKTwwkhhBCinS7dM9ZarwJWtVv3X61ef6Ob6xXy3G43JpOMuSKEEEKGw+zQrbfeysiRIxk2bBgLFy4E4IMPPuCKK64gJyeHiRMnAr5WfbNmzSI7O5vhw4ezfPlygDYt/ZYtW8bdd98NwN13380999zDVVddxYMPPsjnn3/O2LFjyc3N5eqrr2b37t2ArwX1z3/+c7Kyshg7dix/+tOfWLt2Lbfeeqv/uB999BHf/OY3L8efQwghxCXWc0/N/j4XjhV2uXi4xw3Gc4STlA03PnH2MsCrr75KXFwcp06d4sorryQ/P585c+awYcMG0tLSqKqqAuC3v/0tNpuNwkJfPaurq8957LKyMj755BOMRiO1tbV8/PHHmEwm1qxZwyOPPMLy5ctZuHAhBw4cYOvWrZw6dYrm5mbsdjs/+MEPqKioIDExkUWLFvG9733v3H8YIYQQPV7PTcYB9Mc//pEVK1YAcOjQIRYuXMi4ceNIS0sDIC4uDoA1a9bQuq+03W4/57GnT5/u7zfsdDqZOXMme/bsQSlFc3Oz/7j33HOP/zL26fe76667+L//+z9mzZrFpk2bWLx4cTdFLIQQIpB6bjLuwhlsa6e6qT/u+vXrWbNmDZs2bSIiIoK8vDxGjBjBrl27unwMpZT/dWNjY5ttkZGR/te/+tWvuP7661mxYgUHDhw4Z9+5WbNmccstt2C1Wpk+fbrccxZCiBAh94zbcTqd2O12IiIi2LVrF59++imNjY1s2LCB/fv3A/gvU0+aNInnn3/ev+/py9QOh4OdO3fi9Xr9Z9idvVdycjIAr732mn/9pEmTeOmll3C73W3er0+fPvTp04f58+cza9as7gtaCCFEQEkybmfKlCm43W6GDBnC3LlzGTNmDImJiSxcuJDbbruNnJwcZsyYAcCjjz5KdXU1WVlZ5OTksG7dOgCeeOIJbr75Zq6++mp69+7d6Xs9+OCDPPzww+Tm5voTL8Ds2bPp27cvw4cP5+qrr+att97yb7vzzjtJTU1lyJAhl+gvIIQQ4nKT65ztWCwW/v73v3e47cYbb2yzHBUVxeuvv35GuWnTpjFt2rQz1rc++wUYO3YsxcXF/uX5833DeZtMJp5++mmefvrpM4bD3LhxI3PmzOlyPEIIIXo+ScZBZOTIkURGRvKHP/wh0FURQgjRjSQZB5HNmzcHugpCCCEuAblnLIQQQgSYJGMhhBAiwCQZCyGEEAEmyVgIIYQIMEnGQgghRIBJMr4IrWdnau/AgQNkZWVdxtoIIYQIVpKMhRBCiADrsf2Mf//579lV1fXJGTwej382pM4MjhvMQ6Mf6nT73LlzSU1N5Yc//CEA8+bNw2QysW7dOqqrq2lubmb+/Pnk5+d3uV7gmyzi3nvvpaCgwD+61vXXX8+OHTuYNWsWLpcLr9fL8uXL6dOnD7fffjtlZWX+eY1Pz4cshBAiNPXYZBwIM2bM4Cc/+Yk/GS9dupTVq1dz//33ExMTw4kTJxgzZgxTp05tMzPTuTz//PMopSgsLGTXrl3ccMMNFBcX8+KLL/LjH/+YO++8E5fLhcfjYdWqVfTp04f3338f8M1/LIQQIrT12GR8tjPYjrQfw/lC5Obmcvz4cY4cOUJFRQV2u52kpCR++tOfsmHDBgwGA4cPH6a8vJykpKQuH3fjxo3cd999AAwePJh+/fpRXFzM2LFjeeyxxygrK+O2225j4MCBZGdn87Of/YyHHnqIm2++mREjRlxUTEIIIXo+uWfczvTp01m2bBlLlixhxowZvPnmm1RUVLB582a2bt2Kw+E4Y47iC/Wd73yHlStXEh4ezk033cTatWvJzMxky5YtZGdn8+ijj/LEE+c3r7MQQojg02PPjANlxowZzJkzhxMnTvDPf/6TpUuX0qtXL8xmM+vWrePgwYPnfczrrruON998kwkTJlBcXExpaSmDBg1i3759pKenc//991NaWsq2bdsYPHgwcXFxfPe73yU2NpYXX3zxEkQphBCiJ5Fk3M6wYcOoq6sjOTmZ3r17c+edd3LLLbeQnZ3NqFGjGDx48Hkf8wc/+AH33nsv2dnZmEwmXnvtNSwWC0uXLuWNN97AbDaTlJTEI488whdffMEvfvELDAYDZrOZp5566hJEKYQQoieRZNyBwsJC/+uEhAQ2bdrUYbn6+vpOj9G/f3+2b98OgNVqZdGiRWeUmTt3LnPnzm2zbvLkyUyePNm/XFdXd151F0IIEXzknrEQQggRYHJmfJEKCwu566672qyzWCx89tlnAaqREEKIYCPJ+CJlZ2ezdevWQFdDCCFEEJPL1EIIIUSASTIWQgghAkySsRBCCBFgkoyFEEKIAJNkfBHONp+xEEII0VWSjEOA2+0OdBWEEEJchB7btenY44/TtLPr8xm7PR6qzjGfsWXIYJIeeaTT7d05n3F9fT35+fkd7rd48WKeeuoplFIMHz6cN954g/Lycu655x727dsHwAsvvECfPn246aabKCoqAuCpp56ivr6eefPmkZeXx4gRI9i4cSN33HEHmZmZzJ8/H5fLRXx8PG+++SYOh4P6+nruu+8+CgoKUErx61//GqfTybZt23j22WcBePnllykqKuKZZ5459x9aCCFEt+uxyTgQunM+Y6vVyooVK87Yr6ioiPnz5/PJJ5+QkJBAVVUVAPfffz/jx49nxYoVeDwe6uvrqa6uPut7uFwuCgoKAKiurubTTz9FKcUrr7zCk08+yR/+8Ad++9vfYrPZ/EN8VldXYzabeeyxx1iwYAFms5lFixbx0ksvXeyfTwghxAXqscn4bGewHelp8xlrrXnkkUfO2G/t2rVMnz6dhIQEAOLi4gBYu3YtixcvBsBoNGKz2c6ZjGfMmOF/XVZWxowZMzh69Cgul4u0tDQA1qxZw9tvv+0vZ7fbAZgwYQLvvfceQ4YMobm5mezs7PP8awkhhOguPTYZB8rp+YyPHTt2xnzGZrOZ/v37d2k+4wvdrzWTyYTX6/Uvt98/MjLS//q+++7jgQceYOrUqaxfv5558+ad9dizZ8/m8ccfZ/DgwcyaNeu86iWEEKJ7SQOudmbMmMHbb7/NsmXLmD59Ok6n84LmM+5svwkTJvDOO+9QWVkJ4L9MPXHiRF544QUAPB4PTqcTh8NBRUUFlZWVNDU18d577531/ZKTkwF4/fXX/esnTZrE888/718+fbZ91VVXcejQId566y3uuOOOrv55hBBCXAKSjNvpaD7jgoICsrOzWbx4cZfnM+5sv2HDhvHLX/6S8ePHk5OTwwMPPADAc889x7p168jOzmbkyJEUFRVhNpt56KGHGD16NJMmTTrre8+bN4/p06czcuRI/yVwgEcffZTq6mqysrLIyclh3bp1/m23334711xzjf/StRBCiMCQy9Qd6I75jM+238yZM5k5c2abdQ6Hg3ffffeMsvfeey8PPvjgGevXr1/fZjk/P7/DVt5RUVFtzpRb27hxIz/96U87C0EIIcRlImfGX0M1NTVkZmYSHh7OxIkTA10dIYT42pMz44sUjPMZx8bGUlxcHOhqCCGEaCHJ+CLJfMZCCCEuVo+7TK21DnQVRAv5LIQQ4vLoUcnYarVSWVkpSaAH0FpTWVmJ1WoNdFWEECLk9ajL1CkpKZSVlVFRUXHe+zY2NoZk4ghkXFarlZSUlIC8txBCfJ10KRkrpaYAzwFG4BWt9RPttluAxcBIoBKYobU+cL6VMZvN/mEcz9f69evJzc29oH17slCNSwghxL+d8zK1UsoIPA/cCAwF7lBKDW1X7P8B1VrrDOAZ4PfdXVEhhBAiVHXlnvFooERrvU9r7QLeBtqPLpEPnB5ZYhkwUZ1rWiMhhBBCAF1LxsnAoVbLZS3rOiyjtXYDTiC+OyoohBBChLrL2oBLKfV94Psti/VKqd3dePgE4EQ3Hq+nCNW4IHRjk7iCi8QVXII5rn6dbehKMj4MpLZaTmlZ11GZMqWUCbDha8jVhtZ6IbCwC+953pRSBVrrUZfi2IEUqnFB6MYmcQUGDwTTAAAEqElEQVQXiSu4hGpcXblM/QUwUCmVppQKA74NrGxXZiVweuaDacBaLZ2FhRBCiC4555mx1tqtlPoRsBpf16ZXtdY7lFK/AQq01iuB/wXeUEqVAFX4ErYQQgghuqBL94y11quAVe3W/Ver143A9O6t2nm7JJe/e4BQjQtCNzaJK7hIXMElJONScjVZCCGECKweNTa1EEII8XUUEslYKTVFKbVbKVWilJob6PpcKKXUq0qp40qp7a3WxSmlPlJK7Wl5tgeyjhdCKZWqlFqnlCpSSu1QSv24ZX1Qx6aUsiqlPldKfdUS13+3rE9TSn3W8n1c0tLwMegopYxKqS+VUu+1LAd9XEqpA0qpQqXUVqVUQcu6oP4eAiilYpVSy5RSu5RSO5VSY0MkrkEtn9XpR61S6iehEFt7QZ+MuzhcZ7B4DZjSbt1c4B9a64HAP1qWg40b+JnWeigwBvhhy2cU7LE1ARO01jnACGCKUmoMvuFgn2kZHrYa33CxwejHwM5Wy6ES1/Va6xGtuscE+/cQfHMHfKC1Hgzk4Pvcgj4urfXuls9qBL65DxqAFYRAbGfQWgf1AxgLrG61/DDwcKDrdRHx9Ae2t1reDfRued0b2B3oOnZDjO8Ck0IpNiAC2AJchW9AAlPL+jbfz2B54BtP4B/ABOA9QIVIXAeAhHbrgvp7iG9ch/20tAEKlbg6iPMG4F+hGJvWOvjPjOnacJ3BzKG1Ptry+hjgCGRlLpZSqj+QC3xGCMTWcil3K3Ac+AjYC9Ro37CwELzfx2eBBwFvy3I8oRGXBj5USm1uGREQgv97mAZUAItabiu8opSKJPjjau/bwJ9bXodabCGRjL82tO9nYNA2f1dKRQHLgZ9orWtbbwvW2LTWHu27hJaCb1KVwQGu0kVTSt0MHNdabw50XS6Ba7XWV+C7rfVDpdS41huD9HtoAq4AXtBa5wInaXfZNkjj8mtpnzAVeKf9tmCP7bRQSMZdGa4zmJUrpXoDtDwfD3B9LohSyowvEb+ptf5Ly+qQiA1Aa10DrMN3+Ta2ZVhYCM7v4zXAVKXUAXyztE3Ad08y2ONCa3245fk4vnuPown+72EZUKa1/qxleRm+5BzscbV2I7BFa13eshxKsQGhkYy7MlxnMGs91OhMfPdbg0rLdJr/C+zUWj/dalNQx6aUSlRKxba8Dsd3H3wnvqQ8raVY0MWltX5Ya52ite6P79/TWq31nQR5XEqpSKVU9OnX+O5BbifIv4da62PAIaXUoJZVE4Eigjyudu7g35eoIbRiA0Jk0A+l1E347nGdHq7zsQBX6YIopf4M5OGblaQc+DXwV2Ap0Bc4CNyuta4KVB0vhFLqWuBjoJB/34N8BN9946CNTSk1HN883kZ8P2yXaq1/o5RKx3dGGQd8CXxXa90UuJpeOKVUHvBzrfXNwR5XS/1XtCyagLe01o8ppeIJ4u8hgFJqBPAKEAbsA2bR8p0kiOMC/w+nUiBda+1sWRf0n1l7IZGMhRBCiGAWCpephRBCiKAmyVgIIYQIMEnGQgghRIBJMhZCCCECTJKxEEIIEWCSjIUQQogAk2QshBBCBJgkYyGEECLA/j+D/gZcfAlfRwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(history)\n",
    "\n",
    "# 1. 参数众多，训练不充分\n",
    "# 2. 梯度消失 -> 链式法则 -> 复合函数f(g(x))\n",
    "#    批归一化缓解梯度消失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.357668399810791, 0.8744000196456909]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
