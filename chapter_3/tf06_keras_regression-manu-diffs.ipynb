{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
      "matplotlib 3.3.4\n",
      "numpy 1.19.5\n",
      "pandas 1.1.5\n",
      "sklearn 0.24.2\n",
      "tensorflow 2.2.0\n",
      "tensorflow.keras 2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n",
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "print(housing.DESCR)\n",
    "print(housing.data.shape)\n",
    "print(housing.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8) (11610,)\n",
      "(3870, 8) (3870,)\n",
      "(5160, 8) (5160,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state = 7)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train_all, y_train_all, random_state = 11)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.transform(x_valid)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "--------------------------------------------------\n",
      "tf.Tensor(4.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 首先我们看下metric(算子)使用\n",
    "# 掌握reset_states的使用\n",
    "# 模拟每一轮epoch训练的数据其实是将所有batch_size的均方差加起来求平均值\n",
    "metric = keras.metrics.MeanSquaredError()\n",
    "print(metric([5.], [2.]))\n",
    "print('-'*50)\n",
    "print(metric([0.], [1.]))\n",
    "print('-'*50)\n",
    "#具有累加功能，第1个是9，第二个是1，平均是5，(9+1)/2\n",
    "# result()里面的值是metric没有经过reset_states()重置时，里面所有值的平均数\n",
    "print(metric.result())\n",
    "print('-'*50)\n",
    "#不想累加就reset\n",
    "metric.reset_states()  #每次epoch需要reset，相当于清空之前epoch算的\n",
    "metric([1.], [3.])\n",
    "print(metric.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11610\n",
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "#训练集的样本数\n",
    "print(len(x_train_scaled))\n",
    "print(x_train.shape[1:])  #特征数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "362.8125"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11610/32  #每次训练给予的样本数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0 1 2]]\n",
      "\n",
      "  [[3 4 5]]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 3), dtype=int64, numpy=\narray([[0, 1, 2],\n       [3, 4, 5]])>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t= np.arange(6).reshape(1, 2, 1, 3)\n",
    "print(t)\n",
    "tf.squeeze(t)  # [2, 3]  #降维，从张量形状中移除大小为1的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[219 115 580 962 684]\n",
      "[[-2.31468099e-01 -4.82395224e-02  2.75999844e-02  7.94633262e-02\n",
      "  -5.59382726e-01  1.53377321e-02  1.56112088e+00 -1.90503424e+00]\n",
      " [ 7.78472443e-01 -1.08954260e+00  8.45508087e-01 -1.20959861e-03\n",
      "  -1.13905209e-01  3.19084823e-03  1.25318536e+00 -1.37572664e+00]\n",
      " [ 2.02163604e+00 -1.97064520e+00  4.53768873e-01 -7.72085820e-02\n",
      "   1.06919598e+00 -5.25523370e-02 -1.24295862e+00  1.16594852e+00]\n",
      " [-2.62425968e-01  9.93063554e-01 -5.46798793e-01 -9.17670797e-02\n",
      "  -6.51018630e-01 -9.55003183e-02 -7.53061201e-01  5.61738903e-01]\n",
      " [-3.89667607e-01  9.12963317e-01 -2.43600582e-01 -5.17982452e-02\n",
      "  -5.33071426e-01 -1.58033144e-02  1.27184812e+00 -1.57546536e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([1.094, 2.026, 3.37 , 3.181, 1.833])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#随机挑选5个样本，看下特征，标签\n",
    "idx = np.random.randint(0, 1000, size=5)\n",
    "print(idx)\n",
    "print(x_train_scaled[idx])\n",
    "y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]\n",
      " [3]], shape=(3, 1), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# squeeze的作用\n",
    "t=tf.constant([[1],[2],[3]])\n",
    "print(t)\n",
    "# 后面这个1加不加都无所谓\n",
    "tf.squeeze(t,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helloworld\r"
     ]
    }
   ],
   "source": [
    "# 为了在一次epoch内只打印一次损失，模拟官方接口\n",
    "for i in range(10):\n",
    "    print('helloworld',end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义损失函数\n",
    "def customized_mse(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# 自定义激活函数\n",
    "customized_softplus = keras.layers.Lambda(lambda  x: tf.math.log(1+tf.math.exp(x)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#自定义layer\n",
    "class CustomizedDenseLayer(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        '''\n",
    "        初始化\n",
    "        :param units: 输入维度\n",
    "        :param activation: 激活函数\n",
    "        :param kwargs:\n",
    "        '''\n",
    "        super(CustomizedDenseLayer, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.layers.Activation(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        '''\n",
    "        Creates the variables of the layer (optional, for subclass implementers).\n",
    "        :param input_shape: 输入维度\n",
    "        :return: 返回一个自定义的层\n",
    "        '''\n",
    "        self.kernel = self.add_weight(name= 'kernel',\n",
    "                                      shape= (input_shape[1], self.units),\n",
    "                                      initializer= 'uniform',\n",
    "                                      trainable= True)\n",
    "        self.bias = self.add_weight(name= 'bias',\n",
    "                                    shape= (self.units, ),\n",
    "                                    initializer= 'zeros',\n",
    "                                    trainable= True)\n",
    "        super(CustomizedDenseLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.activation(x @ self.kernel + self.bias)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362\n",
      "--------------------------------------------------\n",
      "[<tf.Variable 'customized_dense_layer_2/kernel:0' shape=(8, 30) dtype=float32, numpy=\n",
      "array([[ 3.25188078e-02,  4.95651104e-02, -3.55176814e-02,\n",
      "         4.04045917e-02, -3.12330369e-02, -1.26496069e-02,\n",
      "         2.88982280e-02, -4.61995266e-02,  1.31324567e-02,\n",
      "        -2.38474142e-02, -1.65327191e-02,  1.68738402e-02,\n",
      "         4.20048721e-02,  4.36510779e-02, -2.77848374e-02,\n",
      "         5.46249002e-03, -1.03545897e-02, -2.75423769e-02,\n",
      "         1.07335448e-02, -2.85104997e-02,  1.19488314e-03,\n",
      "         3.33558396e-03,  3.99477743e-02,  4.98084538e-02,\n",
      "         2.62764134e-02, -1.39222369e-02, -4.96409535e-02,\n",
      "         4.15737368e-02,  5.68091869e-04, -4.41354290e-02],\n",
      "       [-1.22189522e-03, -1.85407288e-02, -1.74312368e-02,\n",
      "        -2.95979623e-02,  2.24985220e-02,  3.70680131e-02,\n",
      "         1.08455047e-02, -6.69698790e-03, -5.12184948e-03,\n",
      "         3.52028124e-02, -4.65253741e-03, -5.98502159e-03,\n",
      "        -2.33681202e-02,  6.68394566e-03, -4.31588888e-02,\n",
      "        -1.82173736e-02, -3.81521359e-02,  2.19659097e-02,\n",
      "         4.47945110e-02,  4.87251319e-02, -4.36188839e-02,\n",
      "         2.56901644e-02, -1.44085400e-02, -1.49122365e-02,\n",
      "        -1.82378516e-02,  4.59095277e-02,  2.13468932e-02,\n",
      "         4.87245247e-03,  3.72514762e-02,  4.31737192e-02],\n",
      "       [ 4.01387252e-02,  3.09556164e-02, -4.65371273e-02,\n",
      "        -3.33848149e-02,  1.79075040e-02,  3.72474305e-02,\n",
      "         5.14303520e-03,  8.57472420e-03,  4.79347371e-02,\n",
      "         1.68741085e-02,  2.84448974e-02,  2.15895213e-02,\n",
      "        -2.40375996e-02, -8.11967999e-03,  4.18663882e-02,\n",
      "         1.85684003e-02, -4.70449328e-02, -3.58972177e-02,\n",
      "        -2.33305935e-02,  2.29936950e-02,  1.95800327e-02,\n",
      "        -3.06572765e-03, -3.92151251e-02,  2.38597132e-02,\n",
      "        -4.66961972e-02,  8.42304155e-03, -2.54441984e-02,\n",
      "        -1.88819654e-02,  4.05473150e-02, -1.43510588e-02],\n",
      "       [ 4.64435257e-02, -1.85453184e-02,  1.18719712e-02,\n",
      "         1.72543786e-02, -1.72723755e-02,  2.58502997e-02,\n",
      "         2.98946165e-02, -1.72425136e-02, -2.15241667e-02,\n",
      "         3.37133557e-03,  3.08463089e-02,  2.01579817e-02,\n",
      "         2.06998624e-02,  1.93000697e-02,  2.14447416e-02,\n",
      "        -1.04752183e-02,  3.19508426e-02, -6.19588047e-03,\n",
      "         4.37440313e-02,  3.05886157e-02, -4.38983329e-02,\n",
      "        -3.46183777e-02,  7.89220259e-03,  1.41876452e-02,\n",
      "         4.12449725e-02,  1.91115253e-02,  3.23022641e-02,\n",
      "         2.21307017e-02, -2.16964837e-02, -2.10471153e-02],\n",
      "       [-1.10052936e-02, -2.61088498e-02,  8.84803385e-03,\n",
      "         4.29401435e-02, -1.78606398e-02,  2.39119641e-02,\n",
      "        -4.40328605e-02, -3.17777172e-02, -1.99905168e-02,\n",
      "         4.17930223e-02, -1.29009373e-02,  4.62591089e-02,\n",
      "        -1.96060780e-02, -1.08063109e-02,  2.65910067e-02,\n",
      "         4.07765172e-02,  1.20680444e-02,  7.06203282e-05,\n",
      "         4.99833114e-02,  1.10535845e-02, -3.81365903e-02,\n",
      "         4.41025160e-02,  2.17247270e-02,  3.45922224e-02,\n",
      "         3.60738151e-02,  3.82719673e-02, -3.64254341e-02,\n",
      "         6.32818788e-03,  3.60480435e-02, -3.11776288e-02],\n",
      "       [-4.68868874e-02,  4.13854830e-02, -3.70532274e-02,\n",
      "         4.29915227e-02,  2.45955028e-02, -1.95220243e-02,\n",
      "         1.58437155e-02,  4.93074171e-02, -4.98213619e-03,\n",
      "         2.57754363e-02, -1.37092359e-02,  2.57975496e-02,\n",
      "        -2.95201074e-02,  2.50205509e-02,  2.91918851e-02,\n",
      "         2.41973884e-02, -2.46541258e-02,  2.88265012e-02,\n",
      "        -1.10530369e-02, -4.66160849e-03, -4.67319004e-02,\n",
      "         1.85389556e-02,  1.17696039e-02,  2.12667137e-03,\n",
      "        -1.39983185e-02, -2.36026049e-02, -2.32793223e-02,\n",
      "         1.42488517e-02,  1.82604790e-03,  1.36762857e-03],\n",
      "       [ 2.00286172e-02, -2.44405158e-02,  4.10075448e-02,\n",
      "         4.71496917e-02,  3.48063745e-02, -9.33801010e-03,\n",
      "        -9.18047503e-03,  4.04376052e-02, -4.91633266e-03,\n",
      "        -5.80347702e-03, -1.29974373e-02,  4.34173383e-02,\n",
      "        -6.70939684e-03, -3.54954116e-02, -2.73045655e-02,\n",
      "        -2.78763063e-02,  2.81894840e-02,  4.57990430e-02,\n",
      "         9.96314362e-03,  3.59014757e-02,  4.89315130e-02,\n",
      "         8.02388042e-03, -4.48901579e-03, -1.86196677e-02,\n",
      "        -4.46550138e-02,  2.11929567e-02,  2.63193510e-02,\n",
      "         4.61159013e-02,  6.39091805e-03,  2.57240422e-02],\n",
      "       [ 3.45326103e-02, -4.23831008e-02,  1.16853006e-02,\n",
      "        -1.92280654e-02, -2.47327238e-03, -4.05190364e-02,\n",
      "         2.12880634e-02, -4.21469212e-02,  1.91475041e-02,\n",
      "         1.48554705e-02, -1.36850476e-02, -5.42739779e-03,\n",
      "         3.50062512e-02,  2.12336518e-02,  9.08696651e-03,\n",
      "        -2.31177732e-03, -2.00147163e-02, -4.11027670e-02,\n",
      "        -3.40703279e-02, -4.90228795e-02,  6.82300329e-03,\n",
      "        -1.63544528e-02, -3.20057943e-03, -4.35419939e-02,\n",
      "        -3.79831567e-02, -1.74418688e-02,  4.66411971e-02,\n",
      "         1.43312551e-02,  1.68752111e-02,  1.89725496e-02]], dtype=float32)>, <tf.Variable 'customized_dense_layer_2/bias:0' shape=(30,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'customized_dense_layer_3/kernel:0' shape=(30, 1) dtype=float32, numpy=\n",
      "array([[ 0.04876978],\n",
      "       [-0.04784349],\n",
      "       [ 0.01615648],\n",
      "       [-0.00655125],\n",
      "       [ 0.02579353],\n",
      "       [-0.04318658],\n",
      "       [-0.02680575],\n",
      "       [-0.03666421],\n",
      "       [ 0.01101103],\n",
      "       [ 0.0463799 ],\n",
      "       [ 0.04535573],\n",
      "       [-0.00293953],\n",
      "       [ 0.0091552 ],\n",
      "       [-0.03655208],\n",
      "       [-0.02489226],\n",
      "       [ 0.04734719],\n",
      "       [-0.0277426 ],\n",
      "       [-0.02959906],\n",
      "       [-0.0090901 ],\n",
      "       [-0.04110476],\n",
      "       [-0.02202592],\n",
      "       [-0.01196344],\n",
      "       [ 0.03041141],\n",
      "       [ 0.02434236],\n",
      "       [-0.01802104],\n",
      "       [-0.04161198],\n",
      "       [ 0.01067125],\n",
      "       [ 0.00633252],\n",
      "       [ 0.01657968],\n",
      "       [-0.00609094]], dtype=float32)>, <tf.Variable 'customized_dense_layer_3/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# 1. batch 遍历训练集 metric\n",
    "#    1.1 自动求导\n",
    "# 2. epoch结束 验证集 metric\n",
    "\n",
    "epochs = 5 #训练多少次，没有early_stopping就真的是循环100次\n",
    "batch_size = 32 \n",
    "steps_per_epoch = len(x_train_scaled) // batch_size  #计算每一次epoch有多少个batch\n",
    "print(steps_per_epoch)\n",
    "print('-'*50)\n",
    "optimizer = keras.optimizers.SGD()\n",
    "# 定义算子\n",
    "metric = keras.metrics.MeanSquaredError()\n",
    "\n",
    "#随机取数据,取出来32个样本\n",
    "def random_batch(x, y):\n",
    "    idx = np.random.randint(0, len(x), size=batch_size)\n",
    "    return x[idx], y[idx]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    CustomizedDenseLayer(30, activation=customized_softplus,\n",
    "                         input_shape=x_train.shape[1:]),\n",
    "    CustomizedDenseLayer(1),\n",
    "])\n",
    "# model = keras.models.Sequential([\n",
    "#     keras.layers.Dense(30, activation='relu',\n",
    "#                        input_shape=x_train.shape[1:]),\n",
    "#     keras.layers.Dense(1),\n",
    "# ])\n",
    "print(model.variables)\n",
    "# 这个variables输出的是第一层隐藏层初始化的w和b，第二层输出层初始化的w和b（这个b只有一个0，容易看漏）"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train mse:0.95475894\r\n",
      "\t valid mse:  0.7271466576003275\n",
      "Epoch 1 train mse:0.64742587\rpoch 1 train mse:0.6546194Epoch 1 train mse:0.6552668Epoch 1 train mse:0.649997Epoch 1 train mse:0.64947015Epoch 1 train mse:0.6449426Epoch 1 train mse:0.64381164\r\n",
      "\t valid mse:  0.6813731261811148\n",
      "Epoch 2 train mse:0.58717477\r\n",
      "\t valid mse:  0.6249574592422186\n",
      "Epoch 3 train mse:0.57688236Epoch 3 train mse:0.5771805\r\n",
      "\t valid mse:  0.5895682566296544\n",
      "Epoch 4 train mse:0.55005324\rpoch 4 train mse:0.5493298Epoch 4 train mse:0.55079246Epoch 4 train mse:0.5450721Epoch 4 train mse:0.54520327\r\n",
      "\t valid mse:  0.554914567051243\n"
     ]
    }
   ],
   "source": [
    "#下面一部分相当于替代了fit和compile函数\n",
    "# model.summary()\n",
    "# epochs是模型层数\n",
    "for epoch in range(epochs):#每一轮epochs训练所有的样本\n",
    "    metric.reset_states()  #清空损失\n",
    "    for step in range(steps_per_epoch):  # 这个steps_per_epoch不严谨，因为这个值是整除得到的，意味着其实还有一些数据遗漏了\n",
    "        #随机取32个样本\n",
    "        x_batch, y_batch = random_batch(x_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            #得到预测值\n",
    "            # y_pred是一个shape=(32,1)的张量\n",
    "            # 用model和model.predict是一样作用的，只是使用场景不同\n",
    "            # model时函数式调用，调用的是model的call方法，predict方法时给大规模的batch数据用的，小规模直接用model更快\n",
    "            y_pred = model(x_batch) #等价于model.predict\n",
    " \n",
    "            #删减了值为1的维度,二阶张量，变为一阶张量\n",
    "            # 之所以要变为一阶的是因为标签值是一维的，不是二维的，但(32,1)是二维的，而我们要与标签值运算计算出损失\n",
    "            y_pred = tf.squeeze(y_pred, 1)\n",
    "            #计算损失\n",
    "            loss = keras.losses.mean_squared_error(y_batch, y_pred)\n",
    "            #算子计算均方误差，和上一行代码计算的值一样，只不过会用于不同的用途，上一句用于减小误差，下一句用于打印显示\n",
    "            # 这里的计算得到的值会进入到metric里面\n",
    "            metric(y_batch, y_pred)\n",
    "        #求梯度，不得不说这行代码野心很大，model.variables这么多数据，这里不止对w求导，还对b求导了\n",
    "        grads = tape.gradient(loss, model.variables)\n",
    "        #梯度和变量绑定，对应的变量减去对应的梯度,这个zip的存在是因为apply_gradients对传输进去数据格式的要求\n",
    "        # zip就将对应数据封装成数组里面是元组的格式\n",
    "        grads_and_vars = zip(grads, model.variables)\n",
    "        # 更新，通过，apply_gradients去更新模型的model.variables，也就是更新了w,b\n",
    "        # 不用这个方法还得写for循环\n",
    "        optimizer.apply_gradients(grads_and_vars)\n",
    "        # 看上面的代码有测试metric.result()是啥\n",
    "        # result()里面的值是metric没有经过reset_states()重置时，里面所有值的平均数\n",
    "        p=\"Epoch \"+str(epoch)+\" train mse:\"+str(metric.result().numpy())\n",
    "        #打印，不要在循环内加print，影响\\r\n",
    "        print(p, end='\\r')\n",
    "    print('') #打换行的目的是为了新起一行显示\n",
    "\n",
    "\n",
    "    #搞了一轮训练后，认为模型可以了，去验证集验证，并打印误差\n",
    "    y_valid_pred = model(x_valid_scaled)\n",
    "    # 删减了值为1的维度\n",
    "#     print(y_valid_pred.shape)\n",
    "    y_valid_pred = tf.squeeze(y_valid_pred, 1)\n",
    "#     print(y_valid_pred.shape)\n",
    "    valid_loss = keras.losses.mean_squared_error(y_valid_pred, y_valid)\n",
    "    print(\"\\t\", \"valid mse: \", valid_loss.numpy())\n",
    "        \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}